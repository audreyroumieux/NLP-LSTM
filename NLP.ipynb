{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing  (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnltk.download('punkt')\\nnltk.download('averaged_perceptron_tagger')\\nnltk.download('maxent_ne_chunker')\\nnltk.download('words')\\nnltk.download('wordnet')\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import spacy\n",
    "\n",
    "nlp_fr = spacy.load(\"fr\")\n",
    "nlp_en = spacy.load(\"en\")\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "'''\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Tokenisation (extraire les mots d'un text)\n",
    "\n",
    "### 1.1 - version intuitive (juste un split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = \"\"\"En France, les pionniers en intelligence artificielle (IA) sont Alain Colmerauer, Gérard Huet, Jean-Louis Laurière, Claude-François Picard, Jacques Pitrat et Jean-Claude Simon. \n",
    "Un congrès national annuel, « Reconnaissance de formes et intelligence artificielle », est créé en 1979 à Toulouse. \n",
    "En lien avec l'organisation de la conférence IJCAI (en) à Chambéry en 1993, et la création d'un GRECO-PRC35 « intelligence artificielle », en 1983, il donne naissance à une société savante, l'Association française pour l'intelligence artificielle (AFIA) en 1989, qui, entre autres, organise des conférences nationales en intelligence artificielle.\n",
    "Logo de la conférence « AI for Humanity » organisée le 29 mars 2018 au Collège de France.\n",
    "Au début des années 2000, des sociologues liés à l'EHESS, spécialistes de l'analyse de corpus, expérimentent la mise au point d'un « sociologue numérique » appelé Marlowe qui crée un pont entre intelligence artificielle et sciences sociales.\n",
    "\"\"\"\n",
    "#print(type(text_1))\n",
    "text_2 =\"\"\"Les Fables choisies, mises en vers par M. de La Fontaine, appelées simplement Fables de La Fontaine, sont trois recueils de deux cent quarante trois fables allégoriques publiés par Jean de La Fontaine entre 1668 et 1694. \n",
    "La plupart, inspirées des fables d'Ésope, Babrius et Phèdre, mettent en scène des animaux anthropomorphes et finissent, parfois commencent, par une morale.\n",
    "L'auteur y invente un genre en rupture avec les traditions ésopique, évangélique et humaniste, où le style et l'esprit plus que le propos se veulent didactiques. \n",
    "Modèle du français moderne, ces apologues sont utilisés dès le début du XVIIIe siècle comme support d'enseignement par les jésuites, principal corps enseignant en France jusqu'en 1763, et par les précepteurs familiaux, puis deviennent, sous la Troisième République et jusqu'après-guerre, un incontournable de l'école primaire.\"\"\"\n",
    "\n",
    "text_3 =\"\"\"Le film d'horreur, ou film d'épouvante, est un genre cinématographique dont l'objectif est de créer un sentiment de peur, de répulsion ou d'angoisse chez le spectateur. \n",
    "Il est souvent difficile à dissocier du thriller et surtout du film fantastique, qui apporte une notion de surnaturel sans pour autant avoir pour but de provoquer la peur.\n",
    "Une famille tente de survivre sous la menace de mystérieuses créatures qui attaquent au moindre bruit. S’ils vous entendent, il est déjà trop tard.\n",
    "Un frère et sa soeur sont liés par un terrible secret qui les contraint à ne jamais quitter la maison recluse que leurs parents décédés leur ont laissée en héritage. Un jeune homme va bientôt faire voler cette situation en éclats.\"\"\"\n",
    "\n",
    "text_4 =\"\"\" Retrouvez en détails les règles du jeu de l’Oie. \n",
    "Ce jeu de parcours datant du XVIème siècle est toujours d’actualité pour animer les après-midi des petits et grands.\n",
    "Chaque joueur joue chacun son tour en lançant les 2 dés. \n",
    "Suivant le nombre ou chiffre obtenue, le joueur avance son pion case par case.\n",
    "Il existe des règles du jeu de l’Oie à respecter selon le nombre que l’on fait ou de la case sur laquelle on tombe. \n",
    "Voyons plus en détails ces règles\"\"\"\n",
    "\n",
    "text_5=\"\"\"En règle générale, on amorce beaucoup là ou il y a une quantité importante de poissons, et très peu, ou pas du tout, là où le poisson est rare. Car dans ce cas, il a toute la nourriture nécessaire.\n",
    "Dans l’ignorance, commencer la pêche en appâtant très peu, et augmenter les doses suivant les résultats. Trop d’amorçage fait fuir le poisson.\"\"\"\n",
    "\n",
    "text_6=\"\"\"Pour prévoir le temps qu'il fera demain, il faut déjà connaître le temps qu'il fait aujourd'hui. Plus on veut aller loin dans le temps, plus la zone sur laquelle il faut caractériser le temps qu'il fait doit être étendue. L'observation constitue ainsi la première étape d'une prévision. 90% des données d'observation utilisées par les modèles de prévision de Météo-France proviennent des satellites météorologiques. Les 10% restants sont fournis par des stations au sol, des radiosondages, des capteurs embarqués sur des avions de ligne et des navires de commerce ou installés sur des bouées ancrées et dérivantes. Météo-France reçoit aussi des autres services météorologiques des mesures recueillies sur l'ensemble du globe.\n",
    "Toutes ces observations sont ensuite traitées pour en extraire les informations \"utiles\" au modèle de prévision : on parle d'assimilation des données. Environ 22 millions de données d'observations sont utilisées chaque jour par les modèles à l'issue de l'étape d'assimilation. Les données issues des observations sont combinées à d'autres informations, comme des prévisions très récentes, pour établir un état initial de l'atmosphère que le modèle saura utiliser. Les observations sont également utilisées par les prévisionnistes, d'une part pour le suivi de la situation en cours, d'autre part pour la détection et la correction d'éventuelles erreurs de prévision.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['En', 'France', 'les', 'pionniers', 'en', 'intelligence', 'artificielle', 'IA', 'sont', 'Alain', 'Colmerauer', 'Gérard', 'Huet', 'Jean', 'Louis', 'Laurière', 'Claude', 'François', 'Picard', 'Jacques', 'Pitrat', 'et', 'Jean', 'Claude', 'Simon', 'Un', 'congrès', 'national', 'annuel', 'Reconnaissance', 'de', 'formes', 'et', 'intelligence', 'artificielle', 'est', 'créé', 'en', '1979', 'à', 'Toulouse34', 'En', 'lien', 'avec', 'l', 'organisation', 'de', 'la', 'conférence', 'IJCAI', 'en', 'à', 'Chambéry', 'en', '1993', 'et', 'la', 'création', 'd', 'un', 'GRECO', 'PRC35', 'intelligence', 'artificielle', 'en', '1983', 'il', 'donne', 'naissance', 'à', 'une', 'société', 'savante', 'l', 'Association', 'française', 'pour', 'l', 'intelligence', 'artificielle', 'AFIA', 'en', '1989', 'qui', 'entre', 'autres', 'organise', 'des', 'conférences', 'nationales', 'en', 'intelligence', 'artificielle', 'Logo', 'de', 'la', 'conférence', 'AI', 'for', 'Humanity', 'organisée', 'le', '29', 'mars', '2018', 'au', 'Collège', 'de', 'France', 'Au', 'début', 'des', 'années', '2000', 'des', 'sociologues', 'liés', 'à', 'l', 'EHESS', 'spécialistes', 'de', 'l', 'analyse', 'de', 'corpus', 'expérimentent', 'la', 'mise', 'au', 'point', 'd', 'un', 'sociologue', 'numérique', 'appelé', 'Marlowe', 'qui', 'crée', 'un', 'pont', 'entre', 'intelligence', 'artificielle', 'et', 'sciences', 'sociales', '']\n"
     ]
    }
   ],
   "source": [
    "slplitText = re.split(\"\\W+\", text_1)\n",
    "print(slplitText)\n",
    "#print()\n",
    "#wordDict = dict.fromkeys(set(slplitText), 0)\n",
    "#print(wordDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Segmentation de texte via SpaCy\n",
    "https://github.com/ekino/post-3-nlp/blob/master/Exemples%20de%20t%C3%A2ches%20simples%20de%20NLP%20avec%20SpaCy%20et%20NLTK-run.ipynb\n",
    "\n",
    "https://www.ekino.com/handson-de-quelques-taches-courantes-en-nlp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['En', 'France', ',', 'les', 'pionniers', 'en', 'intelligence', 'artificielle', '(', 'IA', ')', 'sont', 'Alain', 'Colmerauer', ',', 'Gérard', 'Huet', ',', 'Jean', '-', 'Louis', 'Laurière', ',', 'Claude', '-', 'François', 'Picard', ',', 'Jacques', 'Pitrat', 'et', 'Jean', '-', 'Claude', 'Simon', '.', 'Un', 'congrès', 'national', 'annuel', ',', '«', 'Reconnaissance', 'de', 'formes', 'et', 'intelligence', 'artificielle', '»', ',', 'est', 'créé', 'en', '1979', 'à', 'Toulouse34', '.', 'En', 'lien', 'avec', \"l'\", 'organisation', 'de', 'la', 'conférence', 'IJCAI', '(', 'en', ')', 'à', 'Chambéry', 'en', '1993', ',', 'et', 'la', 'création', \"d'\", 'un', 'GRECO', '-', 'PRC35', '«', 'intelligence', 'artificielle', '»', ',', 'en', '1983', ',', 'il', 'donne', 'naissance', 'à', 'une', 'société', 'savante', ',', \"l'\", 'Association', 'française', 'pour', \"l'\", 'intelligence', 'artificielle', '(', 'AFIA', ')', 'en', '1989', ',', 'qui', ',', 'entre', 'autres', ',', 'organise', 'des', 'conférences', 'nationales', 'en', 'intelligence', 'artificielle', '.', '\\n', 'Logo', 'de', 'la', 'conférence', '«', 'AI', 'for', 'Humanity', '»', 'organisée', 'le', '29', 'mars', '2018', 'au', 'Collège', 'de', 'France', '.', '\\n', 'Au', 'début', 'des', 'années', '2000', ',', 'des', 'sociologues', 'liés', 'à', \"l'\", 'EHESS', ',', 'spécialistes', 'de', \"l'\", 'analyse', 'de', 'corpus', ',', 'expérimentent', 'la', 'mise', 'au', 'point', \"d'\", 'un', '«', 'sociologue', 'numérique', '»', 'appelé', 'Marlowe', 'qui', 'crée', 'un', 'pont', 'entre', 'intelligence', 'artificielle', 'et', 'sciences', 'sociales', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "# On passe la phrase par le pipeline\n",
    "doc_fr = nlp_fr(text_1)\n",
    " \n",
    "# On récupère et on affiche les tokens\n",
    "tokens_fr = [w.text for w in doc_fr]\n",
    "print(tokens_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Segmentation de texte via NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['En', 'France', ',', 'les', 'pionniers', 'en', 'intelligence', 'artificielle', '(', 'IA', ')', 'sont', 'Alain', 'Colmerauer', ',', 'Gérard', 'Huet', ',', 'Jean-Louis', 'Laurière', ',', 'Claude-François', 'Picard', ',', 'Jacques', 'Pitrat', 'et', 'Jean-Claude', 'Simon', '.', 'Un', 'congrès', 'national', 'annuel', ',', '«', 'Reconnaissance', 'de', 'formes', 'et', 'intelligence', 'artificielle', '»', ',', 'est', 'créé', 'en', '1979', 'à', 'Toulouse34', '.', 'En', 'lien', 'avec', \"l'organisation\", 'de', 'la', 'conférence', 'IJCAI', '(', 'en', ')', 'à', 'Chambéry', 'en', '1993', ',', 'et', 'la', 'création', \"d'un\", 'GRECO-PRC35', '«', 'intelligence', 'artificielle', '»', ',', 'en', '1983', ',', 'il', 'donne', 'naissance', 'à', 'une', 'société', 'savante', ',', \"l'Association\", 'française', 'pour', \"l'intelligence\", 'artificielle', '(', 'AFIA', ')', 'en', '1989', ',', 'qui', ',', 'entre', 'autres', ',', 'organise', 'des', 'conférences', 'nationales', 'en', 'intelligence', 'artificielle', '.', 'Logo', 'de', 'la', 'conférence', '«', 'AI', 'for', 'Humanity', '»', 'organisée', 'le', '29', 'mars', '2018', 'au', 'Collège', 'de', 'France', '.', 'Au', 'début', 'des', 'années', '2000', ',', 'des', 'sociologues', 'liés', 'à', \"l'EHESS\", ',', 'spécialistes', 'de', \"l'analyse\", 'de', 'corpus', ',', 'expérimentent', 'la', 'mise', 'au', 'point', \"d'un\", '«', 'sociologue', 'numérique', '»', 'appelé', 'Marlowe', 'qui', 'crée', 'un', 'pont', 'entre', 'intelligence', 'artificielle', 'et', 'sciences', 'sociales', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens_fr = word_tokenize(text_1, language = 'french')\n",
    "print(tokens_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dérivation et Lemmatization (Extraction d'informations)\n",
    "\n",
    "\n",
    "### Stemming\n",
    "NLTK : ( Porter stemmer, Lancaster Stemmer, Snowball Stemmer , ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: En  Stem: En\n",
      "Actual: France  Stem: franc\n",
      "Actual: ,  Stem: ,\n",
      "Actual: les  Stem: le\n",
      "Actual: pionniers  Stem: pionnier\n",
      "Actual: en  Stem: en\n",
      "Actual: intelligence  Stem: intellig\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: (  Stem: (\n",
      "Actual: IA  Stem: IA\n",
      "Actual: )  Stem: )\n",
      "Actual: sont  Stem: sont\n",
      "Actual: Alain  Stem: alain\n",
      "Actual: Colmerauer  Stem: colmerau\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Gérard  Stem: gérard\n",
      "Actual: Huet  Stem: huet\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Jean-Louis  Stem: jean-loui\n",
      "Actual: Laurière  Stem: laurièr\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Claude-François  Stem: claude-françoi\n",
      "Actual: Picard  Stem: picard\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Jacques  Stem: jacqu\n",
      "Actual: Pitrat  Stem: pitrat\n",
      "Actual: et  Stem: et\n",
      "Actual: Jean-Claude  Stem: jean-claud\n",
      "Actual: Simon  Stem: simon\n",
      "Actual: .  Stem: .\n",
      "Actual: Un  Stem: Un\n",
      "Actual: congrès  Stem: congrè\n",
      "Actual: national  Stem: nation\n",
      "Actual: annuel  Stem: annuel\n",
      "Actual: ,  Stem: ,\n",
      "Actual: «  Stem: «\n",
      "Actual: Reconnaissance  Stem: reconnaiss\n",
      "Actual: de  Stem: de\n",
      "Actual: formes  Stem: form\n",
      "Actual: et  Stem: et\n",
      "Actual: intelligence  Stem: intellig\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: »  Stem: »\n",
      "Actual: ,  Stem: ,\n",
      "Actual: est  Stem: est\n",
      "Actual: créé  Stem: créé\n",
      "Actual: en  Stem: en\n",
      "Actual: 1979  Stem: 1979\n",
      "Actual: à  Stem: à\n",
      "Actual: Toulouse34  Stem: toulouse34\n",
      "Actual: .  Stem: .\n",
      "Actual: En  Stem: En\n",
      "Actual: lien  Stem: lien\n",
      "Actual: avec  Stem: avec\n",
      "Actual: l'organisation  Stem: l'organis\n",
      "Actual: de  Stem: de\n",
      "Actual: la  Stem: la\n",
      "Actual: conférence  Stem: conférenc\n",
      "Actual: IJCAI  Stem: ijcai\n",
      "Actual: (  Stem: (\n",
      "Actual: en  Stem: en\n",
      "Actual: )  Stem: )\n",
      "Actual: à  Stem: à\n",
      "Actual: Chambéry  Stem: chambéri\n",
      "Actual: en  Stem: en\n",
      "Actual: 1993  Stem: 1993\n",
      "Actual: ,  Stem: ,\n",
      "Actual: et  Stem: et\n",
      "Actual: la  Stem: la\n",
      "Actual: création  Stem: création\n",
      "Actual: d'un  Stem: d'un\n",
      "Actual: GRECO-PRC35  Stem: greco-prc35\n",
      "Actual: «  Stem: «\n",
      "Actual: intelligence  Stem: intellig\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: »  Stem: »\n",
      "Actual: ,  Stem: ,\n",
      "Actual: en  Stem: en\n",
      "Actual: 1983  Stem: 1983\n",
      "Actual: ,  Stem: ,\n",
      "Actual: il  Stem: il\n",
      "Actual: donne  Stem: donn\n",
      "Actual: naissance  Stem: naissanc\n",
      "Actual: à  Stem: à\n",
      "Actual: une  Stem: une\n",
      "Actual: société  Stem: société\n",
      "Actual: savante  Stem: savant\n",
      "Actual: ,  Stem: ,\n",
      "Actual: l'Association  Stem: l'associ\n",
      "Actual: française  Stem: français\n",
      "Actual: pour  Stem: pour\n",
      "Actual: l'intelligence  Stem: l'intellig\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: (  Stem: (\n",
      "Actual: AFIA  Stem: afia\n",
      "Actual: )  Stem: )\n",
      "Actual: en  Stem: en\n",
      "Actual: 1989  Stem: 1989\n",
      "Actual: ,  Stem: ,\n",
      "Actual: qui  Stem: qui\n",
      "Actual: ,  Stem: ,\n",
      "Actual: entre  Stem: entr\n",
      "Actual: autres  Stem: autr\n",
      "Actual: ,  Stem: ,\n",
      "Actual: organise  Stem: organis\n",
      "Actual: des  Stem: de\n",
      "Actual: conférences  Stem: conférenc\n",
      "Actual: nationales  Stem: national\n",
      "Actual: en  Stem: en\n",
      "Actual: intelligence  Stem: intellig\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: .  Stem: .\n",
      "Actual: Logo  Stem: logo\n",
      "Actual: de  Stem: de\n",
      "Actual: la  Stem: la\n",
      "Actual: conférence  Stem: conférenc\n",
      "Actual: «  Stem: «\n",
      "Actual: AI  Stem: AI\n",
      "Actual: for  Stem: for\n",
      "Actual: Humanity  Stem: human\n",
      "Actual: »  Stem: »\n",
      "Actual: organisée  Stem: organisé\n",
      "Actual: le  Stem: le\n",
      "Actual: 29  Stem: 29\n",
      "Actual: mars  Stem: mar\n",
      "Actual: 2018  Stem: 2018\n",
      "Actual: au  Stem: au\n",
      "Actual: Collège  Stem: collèg\n",
      "Actual: de  Stem: de\n",
      "Actual: France  Stem: franc\n",
      "Actual: .  Stem: .\n",
      "Actual: Au  Stem: Au\n",
      "Actual: début  Stem: début\n",
      "Actual: des  Stem: de\n",
      "Actual: années  Stem: anné\n",
      "Actual: 2000  Stem: 2000\n",
      "Actual: ,  Stem: ,\n",
      "Actual: des  Stem: de\n",
      "Actual: sociologues  Stem: sociologu\n",
      "Actual: liés  Stem: lié\n",
      "Actual: à  Stem: à\n",
      "Actual: l'EHESS  Stem: l'ehess\n",
      "Actual: ,  Stem: ,\n",
      "Actual: spécialistes  Stem: spécialist\n",
      "Actual: de  Stem: de\n",
      "Actual: l'analyse  Stem: l'analys\n",
      "Actual: de  Stem: de\n",
      "Actual: corpus  Stem: corpu\n",
      "Actual: ,  Stem: ,\n",
      "Actual: expérimentent  Stem: expériment\n",
      "Actual: la  Stem: la\n",
      "Actual: mise  Stem: mise\n",
      "Actual: au  Stem: au\n",
      "Actual: point  Stem: point\n",
      "Actual: d'un  Stem: d'un\n",
      "Actual: «  Stem: «\n",
      "Actual: sociologue  Stem: sociologu\n",
      "Actual: numérique  Stem: numériqu\n",
      "Actual: »  Stem: »\n",
      "Actual: appelé  Stem: appelé\n",
      "Actual: Marlowe  Stem: marlow\n",
      "Actual: qui  Stem: qui\n",
      "Actual: crée  Stem: crée\n",
      "Actual: un  Stem: un\n",
      "Actual: pont  Stem: pont\n",
      "Actual: entre  Stem: entr\n",
      "Actual: intelligence  Stem: intellig\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: et  Stem: et\n",
      "Actual: sciences  Stem: scienc\n",
      "Actual: sociales  Stem: social\n",
      "Actual: .  Stem: .\n",
      "Actual: En  Stem: en\n",
      "Actual: France  Stem: frant\n",
      "Actual: ,  Stem: ,\n",
      "Actual: les  Stem: les\n",
      "Actual: pionniers  Stem: pionny\n",
      "Actual: en  Stem: en\n",
      "Actual: intelligence  Stem: intellig\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: (  Stem: (\n",
      "Actual: IA  Stem: ia\n",
      "Actual: )  Stem: )\n",
      "Actual: sont  Stem: sont\n",
      "Actual: Alain  Stem: alain\n",
      "Actual: Colmerauer  Stem: colmerau\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Gérard  Stem: gérard\n",
      "Actual: Huet  Stem: huet\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Jean-Louis  Stem: jean-louis\n",
      "Actual: Laurière  Stem: laurièr\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Claude-François  Stem: claude-françois\n",
      "Actual: Picard  Stem: picard\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Jacques  Stem: jacqu\n",
      "Actual: Pitrat  Stem: pit\n",
      "Actual: et  Stem: et\n",
      "Actual: Jean-Claude  Stem: jean-claude\n",
      "Actual: Simon  Stem: simon\n",
      "Actual: .  Stem: .\n",
      "Actual: Un  Stem: un\n",
      "Actual: congrès  Stem: congrè\n",
      "Actual: national  Stem: nat\n",
      "Actual: annuel  Stem: annuel\n",
      "Actual: ,  Stem: ,\n",
      "Actual: «  Stem: «\n",
      "Actual: Reconnaissance  Stem: reconnaiss\n",
      "Actual: de  Stem: de\n",
      "Actual: formes  Stem: form\n",
      "Actual: et  Stem: et\n",
      "Actual: intelligence  Stem: intellig\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: »  Stem: »\n",
      "Actual: ,  Stem: ,\n",
      "Actual: est  Stem: est\n",
      "Actual: créé  Stem: créé\n",
      "Actual: en  Stem: en\n",
      "Actual: 1979  Stem: 1979\n",
      "Actual: à  Stem: à\n",
      "Actual: Toulouse34  Stem: toulouse34\n",
      "Actual: .  Stem: .\n",
      "Actual: En  Stem: en\n",
      "Actual: lien  Stem: lien\n",
      "Actual: avec  Stem: avec\n",
      "Actual: l'organisation  Stem: l'organisation\n",
      "Actual: de  Stem: de\n",
      "Actual: la  Stem: la\n",
      "Actual: conférence  Stem: confér\n",
      "Actual: IJCAI  Stem: ijca\n",
      "Actual: (  Stem: (\n",
      "Actual: en  Stem: en\n",
      "Actual: )  Stem: )\n",
      "Actual: à  Stem: à\n",
      "Actual: Chambéry  Stem: chambéry\n",
      "Actual: en  Stem: en\n",
      "Actual: 1993  Stem: 1993\n",
      "Actual: ,  Stem: ,\n",
      "Actual: et  Stem: et\n",
      "Actual: la  Stem: la\n",
      "Actual: création  Stem: création\n",
      "Actual: d'un  Stem: d'un\n",
      "Actual: GRECO-PRC35  Stem: greco-prc35\n",
      "Actual: «  Stem: «\n",
      "Actual: intelligence  Stem: intellig\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: »  Stem: »\n",
      "Actual: ,  Stem: ,\n",
      "Actual: en  Stem: en\n",
      "Actual: 1983  Stem: 1983\n",
      "Actual: ,  Stem: ,\n",
      "Actual: il  Stem: il\n",
      "Actual: donne  Stem: don\n",
      "Actual: naissance  Stem: naiss\n",
      "Actual: à  Stem: à\n",
      "Actual: une  Stem: un\n",
      "Actual: société  Stem: société\n",
      "Actual: savante  Stem: sav\n",
      "Actual: ,  Stem: ,\n",
      "Actual: l'Association  Stem: l'association\n",
      "Actual: française  Stem: frança\n",
      "Actual: pour  Stem: pour\n",
      "Actual: l'intelligence  Stem: l'intelligence\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: (  Stem: (\n",
      "Actual: AFIA  Stem: af\n",
      "Actual: )  Stem: )\n",
      "Actual: en  Stem: en\n",
      "Actual: 1989  Stem: 1989\n",
      "Actual: ,  Stem: ,\n",
      "Actual: qui  Stem: qui\n",
      "Actual: ,  Stem: ,\n",
      "Actual: entre  Stem: ent\n",
      "Actual: autres  Stem: aut\n",
      "Actual: ,  Stem: ,\n",
      "Actual: organise  Stem: org\n",
      "Actual: des  Stem: des\n",
      "Actual: conférences  Stem: confér\n",
      "Actual: nationales  Stem: nat\n",
      "Actual: en  Stem: en\n",
      "Actual: intelligence  Stem: intellig\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: .  Stem: .\n",
      "Actual: Logo  Stem: logo\n",
      "Actual: de  Stem: de\n",
      "Actual: la  Stem: la\n",
      "Actual: conférence  Stem: confér\n",
      "Actual: «  Stem: «\n",
      "Actual: AI  Stem: ai\n",
      "Actual: for  Stem: for\n",
      "Actual: Humanity  Stem: hum\n",
      "Actual: »  Stem: »\n",
      "Actual: organisée  Stem: organisé\n",
      "Actual: le  Stem: le\n",
      "Actual: 29  Stem: 29\n",
      "Actual: mars  Stem: mar\n",
      "Actual: 2018  Stem: 2018\n",
      "Actual: au  Stem: au\n",
      "Actual: Collège  Stem: collèg\n",
      "Actual: de  Stem: de\n",
      "Actual: France  Stem: frant\n",
      "Actual: .  Stem: .\n",
      "Actual: Au  Stem: au\n",
      "Actual: début  Stem: début\n",
      "Actual: des  Stem: des\n",
      "Actual: années  Stem: anné\n",
      "Actual: 2000  Stem: 2000\n",
      "Actual: ,  Stem: ,\n",
      "Actual: des  Stem: des\n",
      "Actual: sociologues  Stem: sociolog\n",
      "Actual: liés  Stem: lié\n",
      "Actual: à  Stem: à\n",
      "Actual: l'EHESS  Stem: l'ehess\n",
      "Actual: ,  Stem: ,\n",
      "Actual: spécialistes  Stem: spécialistes\n",
      "Actual: de  Stem: de\n",
      "Actual: l'analyse  Stem: l'analyse\n",
      "Actual: de  Stem: de\n",
      "Actual: corpus  Stem: corp\n",
      "Actual: ,  Stem: ,\n",
      "Actual: expérimentent  Stem: expéry\n",
      "Actual: la  Stem: la\n",
      "Actual: mise  Stem: mis\n",
      "Actual: au  Stem: au\n",
      "Actual: point  Stem: point\n",
      "Actual: d'un  Stem: d'un\n",
      "Actual: «  Stem: «\n",
      "Actual: sociologue  Stem: sociolog\n",
      "Actual: numérique  Stem: numér\n",
      "Actual: »  Stem: »\n",
      "Actual: appelé  Stem: appelé\n",
      "Actual: Marlowe  Stem: marlow\n",
      "Actual: qui  Stem: qui\n",
      "Actual: crée  Stem: crée\n",
      "Actual: un  Stem: un\n",
      "Actual: pont  Stem: pont\n",
      "Actual: entre  Stem: ent\n",
      "Actual: intelligence  Stem: intellig\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: et  Stem: et\n",
      "Actual: sciences  Stem: sci\n",
      "Actual: sociales  Stem: soc\n",
      "Actual: .  Stem: .\n",
      "Actual: En  Stem: en\n",
      "Actual: France  Stem: franc\n",
      "Actual: ,  Stem: ,\n",
      "Actual: les  Stem: le\n",
      "Actual: pionniers  Stem: pionni\n",
      "Actual: en  Stem: en\n",
      "Actual: intelligence  Stem: intelligent\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: (  Stem: (\n",
      "Actual: IA  Stem: ia\n",
      "Actual: )  Stem: )\n",
      "Actual: sont  Stem: sont\n",
      "Actual: Alain  Stem: alain\n",
      "Actual: Colmerauer  Stem: colmerau\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Gérard  Stem: gérard\n",
      "Actual: Huet  Stem: huet\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Jean-Louis  Stem: jean-lou\n",
      "Actual: Laurière  Stem: lauri\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Claude-François  Stem: claude-françois\n",
      "Actual: Picard  Stem: picard\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Jacques  Stem: jacqu\n",
      "Actual: Pitrat  Stem: pitrat\n",
      "Actual: et  Stem: et\n",
      "Actual: Jean-Claude  Stem: jean-claud\n",
      "Actual: Simon  Stem: simon\n",
      "Actual: .  Stem: .\n",
      "Actual: Un  Stem: un\n",
      "Actual: congrès  Stem: congres\n",
      "Actual: national  Stem: national\n",
      "Actual: annuel  Stem: annuel\n",
      "Actual: ,  Stem: ,\n",
      "Actual: «  Stem: «\n",
      "Actual: Reconnaissance  Stem: reconnaiss\n",
      "Actual: de  Stem: de\n",
      "Actual: formes  Stem: form\n",
      "Actual: et  Stem: et\n",
      "Actual: intelligence  Stem: intelligent\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: »  Stem: »\n",
      "Actual: ,  Stem: ,\n",
      "Actual: est  Stem: est\n",
      "Actual: créé  Stem: cré\n",
      "Actual: en  Stem: en\n",
      "Actual: 1979  Stem: 1979\n",
      "Actual: à  Stem: à\n",
      "Actual: Toulouse34  Stem: toulouse34\n",
      "Actual: .  Stem: .\n",
      "Actual: En  Stem: en\n",
      "Actual: lien  Stem: lien\n",
      "Actual: avec  Stem: avec\n",
      "Actual: l'organisation  Stem: l'organis\n",
      "Actual: de  Stem: de\n",
      "Actual: la  Stem: la\n",
      "Actual: conférence  Stem: conférent\n",
      "Actual: IJCAI  Stem: ijcai\n",
      "Actual: (  Stem: (\n",
      "Actual: en  Stem: en\n",
      "Actual: )  Stem: )\n",
      "Actual: à  Stem: à\n",
      "Actual: Chambéry  Stem: chambéry\n",
      "Actual: en  Stem: en\n",
      "Actual: 1993  Stem: 1993\n",
      "Actual: ,  Stem: ,\n",
      "Actual: et  Stem: et\n",
      "Actual: la  Stem: la\n",
      "Actual: création  Stem: création\n",
      "Actual: d'un  Stem: d'un\n",
      "Actual: GRECO-PRC35  Stem: greco-prc35\n",
      "Actual: «  Stem: «\n",
      "Actual: intelligence  Stem: intelligent\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: »  Stem: »\n",
      "Actual: ,  Stem: ,\n",
      "Actual: en  Stem: en\n",
      "Actual: 1983  Stem: 1983\n",
      "Actual: ,  Stem: ,\n",
      "Actual: il  Stem: il\n",
      "Actual: donne  Stem: don\n",
      "Actual: naissance  Stem: naissanc\n",
      "Actual: à  Stem: à\n",
      "Actual: une  Stem: une\n",
      "Actual: société  Stem: societ\n",
      "Actual: savante  Stem: sav\n",
      "Actual: ,  Stem: ,\n",
      "Actual: l'Association  Stem: l'associ\n",
      "Actual: française  Stem: français\n",
      "Actual: pour  Stem: pour\n",
      "Actual: l'intelligence  Stem: l'intelligent\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: (  Stem: (\n",
      "Actual: AFIA  Stem: afi\n",
      "Actual: )  Stem: )\n",
      "Actual: en  Stem: en\n",
      "Actual: 1989  Stem: 1989\n",
      "Actual: ,  Stem: ,\n",
      "Actual: qui  Stem: qui\n",
      "Actual: ,  Stem: ,\n",
      "Actual: entre  Stem: entre\n",
      "Actual: autres  Stem: autr\n",
      "Actual: ,  Stem: ,\n",
      "Actual: organise  Stem: organis\n",
      "Actual: des  Stem: de\n",
      "Actual: conférences  Stem: conférent\n",
      "Actual: nationales  Stem: national\n",
      "Actual: en  Stem: en\n",
      "Actual: intelligence  Stem: intelligent\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: .  Stem: .\n",
      "Actual: Logo  Stem: logo\n",
      "Actual: de  Stem: de\n",
      "Actual: la  Stem: la\n",
      "Actual: conférence  Stem: conférent\n",
      "Actual: «  Stem: «\n",
      "Actual: AI  Stem: ai\n",
      "Actual: for  Stem: for\n",
      "Actual: Humanity  Stem: humanity\n",
      "Actual: »  Stem: »\n",
      "Actual: organisée  Stem: organis\n",
      "Actual: le  Stem: le\n",
      "Actual: 29  Stem: 29\n",
      "Actual: mars  Stem: mar\n",
      "Actual: 2018  Stem: 2018\n",
      "Actual: au  Stem: au\n",
      "Actual: Collège  Stem: colleg\n",
      "Actual: de  Stem: de\n",
      "Actual: France  Stem: franc\n",
      "Actual: .  Stem: .\n",
      "Actual: Au  Stem: au\n",
      "Actual: début  Stem: début\n",
      "Actual: des  Stem: de\n",
      "Actual: années  Stem: anné\n",
      "Actual: 2000  Stem: 2000\n",
      "Actual: ,  Stem: ,\n",
      "Actual: des  Stem: de\n",
      "Actual: sociologues  Stem: sociologu\n",
      "Actual: liés  Stem: li\n",
      "Actual: à  Stem: à\n",
      "Actual: l'EHESS  Stem: l'ehess\n",
      "Actual: ,  Stem: ,\n",
      "Actual: spécialistes  Stem: spécial\n",
      "Actual: de  Stem: de\n",
      "Actual: l'analyse  Stem: l'analys\n",
      "Actual: de  Stem: de\n",
      "Actual: corpus  Stem: corpus\n",
      "Actual: ,  Stem: ,\n",
      "Actual: expérimentent  Stem: expérimentent\n",
      "Actual: la  Stem: la\n",
      "Actual: mise  Stem: mis\n",
      "Actual: au  Stem: au\n",
      "Actual: point  Stem: point\n",
      "Actual: d'un  Stem: d'un\n",
      "Actual: «  Stem: «\n",
      "Actual: sociologue  Stem: sociologu\n",
      "Actual: numérique  Stem: numer\n",
      "Actual: »  Stem: »\n",
      "Actual: appelé  Stem: appel\n",
      "Actual: Marlowe  Stem: marlow\n",
      "Actual: qui  Stem: qui\n",
      "Actual: crée  Stem: cré\n",
      "Actual: un  Stem: un\n",
      "Actual: pont  Stem: pont\n",
      "Actual: entre  Stem: entre\n",
      "Actual: intelligence  Stem: intelligent\n",
      "Actual: artificielle  Stem: artificiel\n",
      "Actual: et  Stem: et\n",
      "Actual: sciences  Stem: scienc\n",
      "Actual: sociales  Stem: social\n",
      "Actual: .  Stem: .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "for w in tokens_fr:\n",
    "       print(\"Actual: %s  Stem: %s\" %(w, porter_stemmer.stem(w)))\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "for w in tokens_fr:\n",
    "    print(\"Actual: %s  Stem: %s\" %(w, lancaster_stemmer.stem(w)))\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer(\"french\")\n",
    "for w in tokens_fr:\n",
    "    print(\"Actual: %s  Stem: %s\" %(w, snowball_stemmer.stem(w)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizer in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: En  Stem: En\n",
      "Actual: France  Stem: France\n",
      "Actual: ,  Stem: ,\n",
      "Actual: les  Stem: les\n",
      "Actual: pionniers  Stem: pionniers\n",
      "Actual: en  Stem: en\n",
      "Actual: intelligence  Stem: intelligence\n",
      "Actual: artificielle  Stem: artificielle\n",
      "Actual: (  Stem: (\n",
      "Actual: IA  Stem: IA\n",
      "Actual: )  Stem: )\n",
      "Actual: sont  Stem: sont\n",
      "Actual: Alain  Stem: Alain\n",
      "Actual: Colmerauer  Stem: Colmerauer\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Gérard  Stem: Gérard\n",
      "Actual: Huet  Stem: Huet\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Jean-Louis  Stem: Jean-Louis\n",
      "Actual: Laurière  Stem: Laurière\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Claude-François  Stem: Claude-François\n",
      "Actual: Picard  Stem: Picard\n",
      "Actual: ,  Stem: ,\n",
      "Actual: Jacques  Stem: Jacques\n",
      "Actual: Pitrat  Stem: Pitrat\n",
      "Actual: et  Stem: et\n",
      "Actual: Jean-Claude  Stem: Jean-Claude\n",
      "Actual: Simon  Stem: Simon\n",
      "Actual: .  Stem: .\n",
      "Actual: Un  Stem: Un\n",
      "Actual: congrès  Stem: congrès\n",
      "Actual: national  Stem: national\n",
      "Actual: annuel  Stem: annuel\n",
      "Actual: ,  Stem: ,\n",
      "Actual: «  Stem: «\n",
      "Actual: Reconnaissance  Stem: Reconnaissance\n",
      "Actual: de  Stem: de\n",
      "Actual: formes  Stem: form\n",
      "Actual: et  Stem: et\n",
      "Actual: intelligence  Stem: intelligence\n",
      "Actual: artificielle  Stem: artificielle\n",
      "Actual: »  Stem: »\n",
      "Actual: ,  Stem: ,\n",
      "Actual: est  Stem: est\n",
      "Actual: créé  Stem: créé\n",
      "Actual: en  Stem: en\n",
      "Actual: 1979  Stem: 1979\n",
      "Actual: à  Stem: à\n",
      "Actual: Toulouse34  Stem: Toulouse34\n",
      "Actual: .  Stem: .\n",
      "Actual: En  Stem: En\n",
      "Actual: lien  Stem: lien\n",
      "Actual: avec  Stem: avec\n",
      "Actual: l'organisation  Stem: l'organisation\n",
      "Actual: de  Stem: de\n",
      "Actual: la  Stem: la\n",
      "Actual: conférence  Stem: conférence\n",
      "Actual: IJCAI  Stem: IJCAI\n",
      "Actual: (  Stem: (\n",
      "Actual: en  Stem: en\n",
      "Actual: )  Stem: )\n",
      "Actual: à  Stem: à\n",
      "Actual: Chambéry  Stem: Chambéry\n",
      "Actual: en  Stem: en\n",
      "Actual: 1993  Stem: 1993\n",
      "Actual: ,  Stem: ,\n",
      "Actual: et  Stem: et\n",
      "Actual: la  Stem: la\n",
      "Actual: création  Stem: création\n",
      "Actual: d'un  Stem: d'un\n",
      "Actual: GRECO-PRC35  Stem: GRECO-PRC35\n",
      "Actual: «  Stem: «\n",
      "Actual: intelligence  Stem: intelligence\n",
      "Actual: artificielle  Stem: artificielle\n",
      "Actual: »  Stem: »\n",
      "Actual: ,  Stem: ,\n",
      "Actual: en  Stem: en\n",
      "Actual: 1983  Stem: 1983\n",
      "Actual: ,  Stem: ,\n",
      "Actual: il  Stem: il\n",
      "Actual: donne  Stem: donne\n",
      "Actual: naissance  Stem: naissance\n",
      "Actual: à  Stem: à\n",
      "Actual: une  Stem: une\n",
      "Actual: société  Stem: société\n",
      "Actual: savante  Stem: savante\n",
      "Actual: ,  Stem: ,\n",
      "Actual: l'Association  Stem: l'Association\n",
      "Actual: française  Stem: française\n",
      "Actual: pour  Stem: pour\n",
      "Actual: l'intelligence  Stem: l'intelligence\n",
      "Actual: artificielle  Stem: artificielle\n",
      "Actual: (  Stem: (\n",
      "Actual: AFIA  Stem: AFIA\n",
      "Actual: )  Stem: )\n",
      "Actual: en  Stem: en\n",
      "Actual: 1989  Stem: 1989\n",
      "Actual: ,  Stem: ,\n",
      "Actual: qui  Stem: qui\n",
      "Actual: ,  Stem: ,\n",
      "Actual: entre  Stem: entre\n",
      "Actual: autres  Stem: autres\n",
      "Actual: ,  Stem: ,\n",
      "Actual: organise  Stem: organise\n",
      "Actual: des  Stem: des\n",
      "Actual: conférences  Stem: conférences\n",
      "Actual: nationales  Stem: nationales\n",
      "Actual: en  Stem: en\n",
      "Actual: intelligence  Stem: intelligence\n",
      "Actual: artificielle  Stem: artificielle\n",
      "Actual: .  Stem: .\n",
      "Actual: Logo  Stem: Logo\n",
      "Actual: de  Stem: de\n",
      "Actual: la  Stem: la\n",
      "Actual: conférence  Stem: conférence\n",
      "Actual: «  Stem: «\n",
      "Actual: AI  Stem: AI\n",
      "Actual: for  Stem: for\n",
      "Actual: Humanity  Stem: Humanity\n",
      "Actual: »  Stem: »\n",
      "Actual: organisée  Stem: organisée\n",
      "Actual: le  Stem: le\n",
      "Actual: 29  Stem: 29\n",
      "Actual: mars  Stem: mar\n",
      "Actual: 2018  Stem: 2018\n",
      "Actual: au  Stem: au\n",
      "Actual: Collège  Stem: Collège\n",
      "Actual: de  Stem: de\n",
      "Actual: France  Stem: France\n",
      "Actual: .  Stem: .\n",
      "Actual: Au  Stem: Au\n",
      "Actual: début  Stem: début\n",
      "Actual: des  Stem: des\n",
      "Actual: années  Stem: années\n",
      "Actual: 2000  Stem: 2000\n",
      "Actual: ,  Stem: ,\n",
      "Actual: des  Stem: des\n",
      "Actual: sociologues  Stem: sociologues\n",
      "Actual: liés  Stem: liés\n",
      "Actual: à  Stem: à\n",
      "Actual: l'EHESS  Stem: l'EHESS\n",
      "Actual: ,  Stem: ,\n",
      "Actual: spécialistes  Stem: spécialistes\n",
      "Actual: de  Stem: de\n",
      "Actual: l'analyse  Stem: l'analyse\n",
      "Actual: de  Stem: de\n",
      "Actual: corpus  Stem: corpus\n",
      "Actual: ,  Stem: ,\n",
      "Actual: expérimentent  Stem: expérimentent\n",
      "Actual: la  Stem: la\n",
      "Actual: mise  Stem: mise\n",
      "Actual: au  Stem: au\n",
      "Actual: point  Stem: point\n",
      "Actual: d'un  Stem: d'un\n",
      "Actual: «  Stem: «\n",
      "Actual: sociologue  Stem: sociologue\n",
      "Actual: numérique  Stem: numérique\n",
      "Actual: »  Stem: »\n",
      "Actual: appelé  Stem: appelé\n",
      "Actual: Marlowe  Stem: Marlowe\n",
      "Actual: qui  Stem: qui\n",
      "Actual: crée  Stem: crée\n",
      "Actual: un  Stem: un\n",
      "Actual: pont  Stem: pont\n",
      "Actual: entre  Stem: entre\n",
      "Actual: intelligence  Stem: intelligence\n",
      "Actual: artificielle  Stem: artificielle\n",
      "Actual: et  Stem: et\n",
      "Actual: sciences  Stem: sciences\n",
      "Actual: sociales  Stem: sociales\n",
      "Actual: .  Stem: .\n"
     ]
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "for w in tokens_fr:\n",
    "    print(\"Actual: %s  Stem: %s\" %(w, wnl.lemmatize(w, pos='v')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-Of-Speech Tagging\n",
    "C'est l'association d'un mot à sa classe (verbe, nom, adjectif, ...)\n",
    "\n",
    "http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "##### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : En, , Tag : ADP___\n",
      "Word : France, , Tag : PROPN__Gender=Fem|Number=Sing\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : les, , Tag : DET__Definite=Def|Number=Plur|PronType=Art\n",
      "Word : pionniers, , Tag : NOUN__Gender=Masc|Number=Plur\n",
      "Word : en, , Tag : ADP___\n",
      "Word : intelligence, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : artificielle, , Tag : ADJ__Gender=Fem|Number=Sing\n",
      "Word : (, , Tag : PUNCT___\n",
      "Word : IA, , Tag : NOUN___\n",
      "Word : ), , Tag : PUNCT___\n",
      "Word : sont, , Tag : AUX__Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\n",
      "Word : Alain, , Tag : PROPN__Gender=Masc|Number=Sing\n",
      "Word : Colmerauer, , Tag : PROPN__Gender=Masc|Number=Sing\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : Gérard, , Tag : PROPN__Gender=Masc|Number=Sing\n",
      "Word : Huet, , Tag : PROPN___\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : Jean, , Tag : PROPN__Gender=Fem|Number=Sing\n",
      "Word : -, , Tag : PUNCT___\n",
      "Word : Louis, , Tag : PROPN__Gender=Masc|Number=Sing\n",
      "Word : Laurière, , Tag : PROPN___\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : Claude, , Tag : PROPN___\n",
      "Word : -, , Tag : PUNCT___\n",
      "Word : François, , Tag : PROPN__Gender=Masc|Number=Sing\n",
      "Word : Picard, , Tag : PROPN___\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : Jacques, , Tag : PROPN__Gender=Masc|Number=Sing\n",
      "Word : Pitrat, , Tag : PROPN___\n",
      "Word : et, , Tag : CCONJ___\n",
      "Word : Jean, , Tag : PROPN__Gender=Fem|Number=Sing\n",
      "Word : -, , Tag : PUNCT___\n",
      "Word : Claude, , Tag : PROPN__Number=Sing\n",
      "Word : Simon, , Tag : PROPN__Gender=Masc|Number=Sing\n",
      "Word : ., , Tag : PUNCT___\n",
      "Word : Un, , Tag : DET__Definite=Ind|Gender=Masc|Number=Sing|PronType=Art\n",
      "Word : congrès, , Tag : NOUN__Gender=Masc|Number=Sing\n",
      "Word : national, , Tag : ADJ__Gender=Masc|Number=Sing\n",
      "Word : annuel, , Tag : ADJ__Gender=Masc|Number=Sing\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : «, , Tag : PUNCT___\n",
      "Word : Reconnaissance, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : de, , Tag : ADP___\n",
      "Word : formes, , Tag : NOUN__Gender=Fem|Number=Plur\n",
      "Word : et, , Tag : CCONJ___\n",
      "Word : intelligence, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : artificielle, , Tag : ADJ__Gender=Fem|Number=Sing\n",
      "Word : », , Tag : PUNCT___\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : est, , Tag : AUX__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "Word : créé, , Tag : VERB__Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part|Voice=Pass\n",
      "Word : en, , Tag : ADP___\n",
      "Word : 1979, , Tag : NUM__NumType=Card\n",
      "Word : à, , Tag : ADP___\n",
      "Word : Toulouse34, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : ., , Tag : PUNCT___\n",
      "Word : En, , Tag : ADP___\n",
      "Word : lien, , Tag : NOUN__Gender=Masc|Number=Sing\n",
      "Word : avec, , Tag : ADP___\n",
      "Word : l', , Tag : DET__Definite=Def|Number=Sing|PronType=Art\n",
      "Word : organisation, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : de, , Tag : ADP___\n",
      "Word : la, , Tag : DET__Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
      "Word : conférence, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : IJCAI, , Tag : ADJ___\n",
      "Word : (, , Tag : PUNCT___\n",
      "Word : en, , Tag : NOUN___\n",
      "Word : ), , Tag : PUNCT___\n",
      "Word : à, , Tag : ADP___\n",
      "Word : Chambéry, , Tag : PROPN__Gender=Masc|Number=Sing\n",
      "Word : en, , Tag : ADP___\n",
      "Word : 1993, , Tag : NUM__NumType=Card\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : et, , Tag : CCONJ___\n",
      "Word : la, , Tag : DET__Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
      "Word : création, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : d', , Tag : ADP___\n",
      "Word : un, , Tag : DET__Definite=Ind|Gender=Masc|Number=Sing|PronType=Art\n",
      "Word : GRECO, , Tag : NOUN__Gender=Masc|Number=Sing\n",
      "Word : -, , Tag : PUNCT___\n",
      "Word : PRC35, , Tag : PROPN___\n",
      "Word : «, , Tag : PUNCT___\n",
      "Word : intelligence, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : artificielle, , Tag : ADJ__Gender=Fem|Number=Sing\n",
      "Word : », , Tag : PUNCT___\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : en, , Tag : ADP___\n",
      "Word : 1983, , Tag : NUM__NumType=Card\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : il, , Tag : PRON__Gender=Masc|Number=Sing|Person=3\n",
      "Word : donne, , Tag : VERB__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "Word : naissance, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : à, , Tag : ADP___\n",
      "Word : une, , Tag : DET__Definite=Ind|Gender=Fem|Number=Sing|PronType=Art\n",
      "Word : société, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : savante, , Tag : ADJ__Gender=Fem|Number=Sing\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : l', , Tag : DET__Definite=Def|Number=Sing|PronType=Art\n",
      "Word : Association, , Tag : PROPN__Number=Sing\n",
      "Word : française, , Tag : ADJ__Gender=Fem|Number=Sing\n",
      "Word : pour, , Tag : ADP___\n",
      "Word : l', , Tag : DET__Definite=Def|Number=Sing|PronType=Art\n",
      "Word : intelligence, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : artificielle, , Tag : ADJ__Gender=Fem|Number=Sing\n",
      "Word : (, , Tag : PUNCT___\n",
      "Word : AFIA, , Tag : NOUN__Gender=Masc|Number=Sing\n",
      "Word : ), , Tag : PUNCT___\n",
      "Word : en, , Tag : ADP___\n",
      "Word : 1989, , Tag : NUM__NumType=Card\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : qui, , Tag : PRON__PronType=Rel\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : entre, , Tag : ADP___\n",
      "Word : autres, , Tag : ADJ__Number=Plur\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : organise, , Tag : VERB__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "Word : des, , Tag : DET__Definite=Ind|Number=Plur|PronType=Art\n",
      "Word : conférences, , Tag : NOUN__Gender=Fem|Number=Plur\n",
      "Word : nationales, , Tag : ADJ__Gender=Fem|Number=Plur\n",
      "Word : en, , Tag : ADP___\n",
      "Word : intelligence, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : artificielle, , Tag : ADJ__Gender=Fem|Number=Sing\n",
      "Word : ., , Tag : PUNCT___\n",
      "Word : \n",
      ", , Tag : \n",
      "Word : Logo, , Tag : PROPN__Gender=Masc|Number=Sing\n",
      "Word : de, , Tag : ADP___\n",
      "Word : la, , Tag : DET__Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
      "Word : conférence, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : «, , Tag : PUNCT___\n",
      "Word : AI, , Tag : PROPN___\n",
      "Word : for, , Tag : X___\n",
      "Word : Humanity, , Tag : PROPN___\n",
      "Word : », , Tag : PUNCT___\n",
      "Word : organisée, , Tag : VERB__Gender=Fem|Number=Sing|Tense=Past|VerbForm=Part\n",
      "Word : le, , Tag : DET__Definite=Def|Gender=Masc|Number=Sing|PronType=Art\n",
      "Word : 29, , Tag : NUM__NumType=Card\n",
      "Word : mars, , Tag : NOUN__Gender=Masc|Number=Sing\n",
      "Word : 2018, , Tag : NUM__NumType=Card\n",
      "Word : au, , Tag : NOUN__Number=Plur\n",
      "Word : Collège, , Tag : PROPN__Gender=Masc|Number=Sing\n",
      "Word : de, , Tag : ADP___\n",
      "Word : France, , Tag : PROPN__Gender=Fem|Number=Sing\n",
      "Word : ., , Tag : PUNCT___\n",
      "Word : \n",
      ", , Tag : \n",
      "Word : Au, , Tag : ADJ__NumType=Ord\n",
      "Word : début, , Tag : NOUN__Gender=Masc|Number=Sing\n",
      "Word : des, , Tag : DET__Definite=Ind|Number=Plur|PronType=Art\n",
      "Word : années, , Tag : NOUN__Gender=Fem|Number=Plur\n",
      "Word : 2000, , Tag : NUM__NumType=Card\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : des, , Tag : DET__Definite=Ind|Number=Plur|PronType=Art\n",
      "Word : sociologues, , Tag : NOUN__Number=Plur\n",
      "Word : liés, , Tag : VERB__Gender=Masc|Number=Plur|Tense=Past|VerbForm=Part\n",
      "Word : à, , Tag : ADP___\n",
      "Word : l', , Tag : DET__Definite=Def|Number=Sing|PronType=Art\n",
      "Word : EHESS, , Tag : NOUN__Gender=Masc|Number=Sing\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : spécialistes, , Tag : NOUN__Number=Plur\n",
      "Word : de, , Tag : ADP___\n",
      "Word : l', , Tag : DET__Definite=Def|Number=Sing|PronType=Art\n",
      "Word : analyse, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : de, , Tag : ADP___\n",
      "Word : corpus, , Tag : NOUN__Gender=Masc|Number=Sing\n",
      "Word : ,, , Tag : PUNCT___\n",
      "Word : expérimentent, , Tag : VERB__Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\n",
      "Word : la, , Tag : DET__Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
      "Word : mise, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : au, , Tag : DET__Gender=Masc|Number=Sing|PronType=Dem\n",
      "Word : point, , Tag : NOUN__Gender=Masc|Number=Sing\n",
      "Word : d', , Tag : ADP___\n",
      "Word : un, , Tag : DET__Definite=Ind|Gender=Masc|Number=Sing|PronType=Art\n",
      "Word : «, , Tag : PUNCT___\n",
      "Word : sociologue, , Tag : NOUN__Gender=Masc|Number=Sing\n",
      "Word : numérique, , Tag : ADJ__Number=Sing\n",
      "Word : », , Tag : PUNCT___\n",
      "Word : appelé, , Tag : AUX__Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part\n",
      "Word : Marlowe, , Tag : PROPN__Gender=Masc|Number=Sing\n",
      "Word : qui, , Tag : PRON__PronType=Rel\n",
      "Word : crée, , Tag : VERB__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "Word : un, , Tag : DET__Definite=Ind|Gender=Masc|Number=Sing|PronType=Art\n",
      "Word : pont, , Tag : NOUN__Gender=Masc|Number=Sing\n",
      "Word : entre, , Tag : ADP___\n",
      "Word : intelligence, , Tag : NOUN__Gender=Fem|Number=Sing\n",
      "Word : artificielle, , Tag : ADJ__Gender=Fem|Number=Sing\n",
      "Word : et, , Tag : CCONJ___\n",
      "Word : sciences, , Tag : NOUN__Gender=Fem|Number=Plur\n",
      "Word : sociales, , Tag : ADJ__Gender=Fem|Number=Plur\n",
      "Word : ., , Tag : PUNCT___\n",
      "Word : \n",
      ", , Tag : \n"
     ]
    }
   ],
   "source": [
    "# Affichage de chaque token de la phase française suivi de son tag \n",
    "for token in doc_fr:\n",
    "    print('Word : {0}, , Tag : {1}' .format(token.text, token.tag_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('En', 'NNP'), ('France', 'NNP'), (',', ','), ('les', 'VBZ'), ('pionniers', 'NNS'), ('en', 'FW'), ('intelligence', 'NN'), ('artificielle', 'NN'), ('(', '('), ('IA', 'NNP'), (')', ')'), ('sont', 'NN'), ('Alain', 'NNP'), ('Colmerauer', 'NNP'), (',', ','), ('Gérard', 'NNP'), ('Huet', 'NNP'), (',', ','), ('Jean-Louis', 'NNP'), ('Laurière', 'NNP'), (',', ','), ('Claude-François', 'NNP'), ('Picard', 'NNP'), (',', ','), ('Jacques', 'NNP'), ('Pitrat', 'NNP'), ('et', 'VBZ'), ('Jean-Claude', 'NNP'), ('Simon', 'NNP'), ('.', '.'), ('Un', 'NNP'), ('congrès', 'JJ'), ('national', 'JJ'), ('annuel', 'NN'), (',', ','), ('«', 'JJ'), ('Reconnaissance', 'NNP'), ('de', 'FW'), ('formes', 'FW'), ('et', 'FW'), ('intelligence', 'NN'), ('artificielle', 'NN'), ('»', 'NNP'), (',', ','), ('est', 'JJS'), ('créé', 'NN'), ('en', 'NN'), ('1979', 'CD'), ('à', 'NN'), ('Toulouse34', 'NNP'), ('.', '.'), ('En', 'NNP'), ('lien', 'NN'), ('avec', 'JJ'), (\"l'organisation\", 'NN'), ('de', 'IN'), ('la', 'FW'), ('conférence', 'NN'), ('IJCAI', 'NNP'), ('(', '('), ('en', 'FW'), (')', ')'), ('à', 'FW'), ('Chambéry', 'NNP'), ('en', 'IN'), ('1993', 'CD'), (',', ','), ('et', 'CC'), ('la', 'JJS'), ('création', 'NN'), (\"d'un\", 'NN'), ('GRECO-PRC35', 'NNP'), ('«', 'NNP'), ('intelligence', 'NN'), ('artificielle', 'NN'), ('»', 'NNP'), (',', ','), ('en', 'NN'), ('1983', 'CD'), (',', ','), ('il', 'VBP'), ('donne', 'JJ'), ('naissance', 'NN'), ('à', 'NNP'), ('une', 'JJ'), ('société', 'NN'), ('savante', 'NN'), (',', ','), (\"l'Association\", 'NN'), ('française', 'RB'), ('pour', 'JJ'), (\"l'intelligence\", 'NN'), ('artificielle', 'NN'), ('(', '('), ('AFIA', 'NNP'), (')', ')'), ('en', 'NN'), ('1989', 'CD'), (',', ','), ('qui', 'NN'), (',', ','), ('entre', 'JJ'), ('autres', 'NNS'), (',', ','), ('organise', 'NN'), ('des', 'NNS'), ('conférences', 'NNS'), ('nationales', 'NNS'), ('en', 'VBP'), ('intelligence', 'NN'), ('artificielle', 'NN'), ('.', '.'), ('Logo', 'NNP'), ('de', 'IN'), ('la', 'FW'), ('conférence', 'NN'), ('«', 'NN'), ('AI', 'NNP'), ('for', 'IN'), ('Humanity', 'NNP'), ('»', 'NNP'), ('organisée', 'VBD'), ('le', 'JJ'), ('29', 'CD'), ('mars', 'NNS'), ('2018', 'CD'), ('au', 'JJ'), ('Collège', 'NNP'), ('de', 'FW'), ('France', 'NNP'), ('.', '.'), ('Au', 'NNP'), ('début', 'NN'), ('des', 'NNS'), ('années', 'IN'), ('2000', 'CD'), (',', ','), ('des', 'VBZ'), ('sociologues', 'NNS'), ('liés', 'RBR'), ('à', 'NNP'), (\"l'EHESS\", 'NN'), (',', ','), ('spécialistes', 'VBZ'), ('de', 'FW'), (\"l'analyse\", 'FW'), ('de', 'FW'), ('corpus', 'NN'), (',', ','), ('expérimentent', 'JJ'), ('la', 'NN'), ('mise', 'NN'), ('au', 'NN'), ('point', 'NN'), (\"d'un\", 'NN'), ('«', 'NNP'), ('sociologue', 'NN'), ('numérique', 'NN'), ('»', 'NNP'), ('appelé', 'NN'), ('Marlowe', 'NNP'), ('qui', 'NN'), ('crée', 'NN'), ('un', 'JJ'), ('pont', 'NN'), ('entre', 'JJ'), ('intelligence', 'NN'), ('artificielle', 'NN'), ('et', 'NN'), ('sciences', 'NNS'), ('sociales', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tags_fr = pos_tag(tokens_fr) # On tague les tokens\n",
    "print (tags_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconnaissance d’entités nommées (Named-Entity Recognition)\n",
    "trouvent les mots qui correspondent à un ou des concepts catégorisables (noms de personnes, lieux, organisations,…)\n",
    "##### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : En, , Entity : \n",
      "Word : France, , Entity : LOC\n",
      "Word : ,, , Entity : \n",
      "Word : les, , Entity : \n",
      "Word : pionniers, , Entity : \n",
      "Word : en, , Entity : \n",
      "Word : intelligence, , Entity : \n",
      "Word : artificielle, , Entity : \n",
      "Word : (, , Entity : \n",
      "Word : IA, , Entity : \n",
      "Word : ), , Entity : \n",
      "Word : sont, , Entity : \n",
      "Word : Alain, , Entity : PER\n",
      "Word : Colmerauer, , Entity : PER\n",
      "Word : ,, , Entity : \n",
      "Word : Gérard, , Entity : PER\n",
      "Word : Huet, , Entity : PER\n",
      "Word : ,, , Entity : \n",
      "Word : Jean, , Entity : PER\n",
      "Word : -, , Entity : \n",
      "Word : Louis, , Entity : PER\n",
      "Word : Laurière, , Entity : PER\n",
      "Word : ,, , Entity : \n",
      "Word : Claude, , Entity : PER\n",
      "Word : -, , Entity : \n",
      "Word : François, , Entity : PER\n",
      "Word : Picard, , Entity : PER\n",
      "Word : ,, , Entity : \n",
      "Word : Jacques, , Entity : PER\n",
      "Word : Pitrat, , Entity : PER\n",
      "Word : et, , Entity : \n",
      "Word : Jean, , Entity : PER\n",
      "Word : -, , Entity : \n",
      "Word : Claude, , Entity : PER\n",
      "Word : Simon, , Entity : PER\n",
      "Word : ., , Entity : \n",
      "Word : Un, , Entity : \n",
      "Word : congrès, , Entity : \n",
      "Word : national, , Entity : \n",
      "Word : annuel, , Entity : \n",
      "Word : ,, , Entity : \n",
      "Word : «, , Entity : \n",
      "Word : Reconnaissance, , Entity : \n",
      "Word : de, , Entity : \n",
      "Word : formes, , Entity : \n",
      "Word : et, , Entity : \n",
      "Word : intelligence, , Entity : \n",
      "Word : artificielle, , Entity : \n",
      "Word : », , Entity : \n",
      "Word : ,, , Entity : \n",
      "Word : est, , Entity : \n",
      "Word : créé, , Entity : \n",
      "Word : en, , Entity : \n",
      "Word : 1979, , Entity : \n",
      "Word : à, , Entity : \n",
      "Word : Toulouse34, , Entity : MISC\n",
      "Word : ., , Entity : \n",
      "Word : En, , Entity : \n",
      "Word : lien, , Entity : \n",
      "Word : avec, , Entity : \n",
      "Word : l', , Entity : \n",
      "Word : organisation, , Entity : \n",
      "Word : de, , Entity : \n",
      "Word : la, , Entity : \n",
      "Word : conférence, , Entity : \n",
      "Word : IJCAI, , Entity : MISC\n",
      "Word : (, , Entity : \n",
      "Word : en, , Entity : \n",
      "Word : ), , Entity : \n",
      "Word : à, , Entity : \n",
      "Word : Chambéry, , Entity : LOC\n",
      "Word : en, , Entity : \n",
      "Word : 1993, , Entity : \n",
      "Word : ,, , Entity : \n",
      "Word : et, , Entity : \n",
      "Word : la, , Entity : \n",
      "Word : création, , Entity : \n",
      "Word : d', , Entity : \n",
      "Word : un, , Entity : \n",
      "Word : GRECO, , Entity : MISC\n",
      "Word : -, , Entity : \n",
      "Word : PRC35, , Entity : MISC\n",
      "Word : «, , Entity : \n",
      "Word : intelligence, , Entity : \n",
      "Word : artificielle, , Entity : \n",
      "Word : », , Entity : \n",
      "Word : ,, , Entity : \n",
      "Word : en, , Entity : \n",
      "Word : 1983, , Entity : \n",
      "Word : ,, , Entity : \n",
      "Word : il, , Entity : \n",
      "Word : donne, , Entity : \n",
      "Word : naissance, , Entity : \n",
      "Word : à, , Entity : \n",
      "Word : une, , Entity : \n",
      "Word : société, , Entity : \n",
      "Word : savante, , Entity : \n",
      "Word : ,, , Entity : \n",
      "Word : l', , Entity : \n",
      "Word : Association, , Entity : ORG\n",
      "Word : française, , Entity : ORG\n",
      "Word : pour, , Entity : \n",
      "Word : l', , Entity : \n",
      "Word : intelligence, , Entity : \n",
      "Word : artificielle, , Entity : \n",
      "Word : (, , Entity : \n",
      "Word : AFIA, , Entity : ORG\n",
      "Word : ), , Entity : \n",
      "Word : en, , Entity : \n",
      "Word : 1989, , Entity : \n",
      "Word : ,, , Entity : \n",
      "Word : qui, , Entity : \n",
      "Word : ,, , Entity : \n",
      "Word : entre, , Entity : \n",
      "Word : autres, , Entity : \n",
      "Word : ,, , Entity : \n",
      "Word : organise, , Entity : \n",
      "Word : des, , Entity : \n",
      "Word : conférences, , Entity : \n",
      "Word : nationales, , Entity : \n",
      "Word : en, , Entity : \n",
      "Word : intelligence, , Entity : \n",
      "Word : artificielle, , Entity : \n",
      "Word : ., , Entity : \n",
      "Word : \n",
      ", , Entity : \n",
      "Word : Logo, , Entity : \n",
      "Word : de, , Entity : \n",
      "Word : la, , Entity : \n",
      "Word : conférence, , Entity : \n",
      "Word : «, , Entity : \n",
      "Word : AI, , Entity : MISC\n",
      "Word : for, , Entity : MISC\n",
      "Word : Humanity, , Entity : MISC\n",
      "Word : », , Entity : \n",
      "Word : organisée, , Entity : \n",
      "Word : le, , Entity : \n",
      "Word : 29, , Entity : \n",
      "Word : mars, , Entity : \n",
      "Word : 2018, , Entity : \n",
      "Word : au, , Entity : \n",
      "Word : Collège, , Entity : LOC\n",
      "Word : de, , Entity : LOC\n",
      "Word : France, , Entity : LOC\n",
      "Word : ., , Entity : \n",
      "Word : \n",
      ", , Entity : \n",
      "Word : Au, , Entity : \n",
      "Word : début, , Entity : \n",
      "Word : des, , Entity : \n",
      "Word : années, , Entity : \n",
      "Word : 2000, , Entity : \n",
      "Word : ,, , Entity : \n",
      "Word : des, , Entity : \n",
      "Word : sociologues, , Entity : \n",
      "Word : liés, , Entity : \n",
      "Word : à, , Entity : \n",
      "Word : l', , Entity : \n",
      "Word : EHESS, , Entity : ORG\n",
      "Word : ,, , Entity : \n",
      "Word : spécialistes, , Entity : \n",
      "Word : de, , Entity : \n",
      "Word : l', , Entity : \n",
      "Word : analyse, , Entity : \n",
      "Word : de, , Entity : \n",
      "Word : corpus, , Entity : \n",
      "Word : ,, , Entity : \n",
      "Word : expérimentent, , Entity : \n",
      "Word : la, , Entity : \n",
      "Word : mise, , Entity : \n",
      "Word : au, , Entity : \n",
      "Word : point, , Entity : \n",
      "Word : d', , Entity : \n",
      "Word : un, , Entity : \n",
      "Word : «, , Entity : \n",
      "Word : sociologue, , Entity : \n",
      "Word : numérique, , Entity : \n",
      "Word : », , Entity : \n",
      "Word : appelé, , Entity : \n",
      "Word : Marlowe, , Entity : MISC\n",
      "Word : qui, , Entity : \n",
      "Word : crée, , Entity : \n",
      "Word : un, , Entity : \n",
      "Word : pont, , Entity : \n",
      "Word : entre, , Entity : \n",
      "Word : intelligence, , Entity : \n",
      "Word : artificielle, , Entity : \n",
      "Word : et, , Entity : \n",
      "Word : sciences, , Entity : \n",
      "Word : sociales, , Entity : \n",
      "Word : ., , Entity : \n",
      "Word : \n",
      ", , Entity : LOC\n"
     ]
    }
   ],
   "source": [
    "# On affiche chaque token et si une entité est reconnue, on affiche le type d’entité\n",
    "for token in doc_fr:\n",
    "    print('Word : {0}, , Entity : {1}' .format(token.text, token.ent_type_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  En/NNP\n",
      "  (GPE France/NNP)\n",
      "  ,/,\n",
      "  les/VBZ\n",
      "  pionniers/NNS\n",
      "  en/FW\n",
      "  intelligence/NN\n",
      "  artificielle/NN\n",
      "  (/(\n",
      "  IA/NNP\n",
      "  )/)\n",
      "  sont/NN\n",
      "  (PERSON Alain/NNP Colmerauer/NNP)\n",
      "  ,/,\n",
      "  (PERSON Gérard/NNP Huet/NNP)\n",
      "  ,/,\n",
      "  (PERSON Jean-Louis/NNP Laurière/NNP)\n",
      "  ,/,\n",
      "  Claude-François/NNP\n",
      "  (PERSON Picard/NNP)\n",
      "  ,/,\n",
      "  (PERSON Jacques/NNP Pitrat/NNP)\n",
      "  et/VBZ\n",
      "  Jean-Claude/NNP\n",
      "  Simon/NNP\n",
      "  ./.\n",
      "  Un/NNP\n",
      "  congrès/JJ\n",
      "  national/JJ\n",
      "  annuel/NN\n",
      "  ,/,\n",
      "  «/JJ\n",
      "  Reconnaissance/NNP\n",
      "  de/FW\n",
      "  formes/FW\n",
      "  et/FW\n",
      "  intelligence/NN\n",
      "  artificielle/NN\n",
      "  »/NNP\n",
      "  ,/,\n",
      "  est/JJS\n",
      "  créé/NN\n",
      "  en/NN\n",
      "  1979/CD\n",
      "  à/NN\n",
      "  Toulouse34/NNP\n",
      "  ./.\n",
      "  En/NNP\n",
      "  lien/NN\n",
      "  avec/JJ\n",
      "  l'organisation/NN\n",
      "  de/IN\n",
      "  la/FW\n",
      "  conférence/NN\n",
      "  (ORGANIZATION IJCAI/NNP)\n",
      "  (/(\n",
      "  en/FW\n",
      "  )/)\n",
      "  à/FW\n",
      "  Chambéry/NNP\n",
      "  en/IN\n",
      "  1993/CD\n",
      "  ,/,\n",
      "  et/CC\n",
      "  la/JJS\n",
      "  création/NN\n",
      "  d'un/NN\n",
      "  GRECO-PRC35/NNP\n",
      "  «/NNP\n",
      "  intelligence/NN\n",
      "  artificielle/NN\n",
      "  »/NNP\n",
      "  ,/,\n",
      "  en/NN\n",
      "  1983/CD\n",
      "  ,/,\n",
      "  il/VBP\n",
      "  donne/JJ\n",
      "  naissance/NN\n",
      "  à/NNP\n",
      "  une/JJ\n",
      "  société/NN\n",
      "  savante/NN\n",
      "  ,/,\n",
      "  l'Association/NN\n",
      "  française/RB\n",
      "  pour/JJ\n",
      "  l'intelligence/NN\n",
      "  artificielle/NN\n",
      "  (/(\n",
      "  (ORGANIZATION AFIA/NNP)\n",
      "  )/)\n",
      "  en/NN\n",
      "  1989/CD\n",
      "  ,/,\n",
      "  qui/NN\n",
      "  ,/,\n",
      "  entre/JJ\n",
      "  autres/NNS\n",
      "  ,/,\n",
      "  organise/NN\n",
      "  des/NNS\n",
      "  conférences/NNS\n",
      "  nationales/NNS\n",
      "  en/VBP\n",
      "  intelligence/NN\n",
      "  artificielle/NN\n",
      "  ./.\n",
      "  (PERSON Logo/NNP)\n",
      "  de/IN\n",
      "  la/FW\n",
      "  conférence/NN\n",
      "  «/NN\n",
      "  AI/NNP\n",
      "  for/IN\n",
      "  (ORGANIZATION Humanity/NNP)\n",
      "  »/NNP\n",
      "  organisée/VBD\n",
      "  le/JJ\n",
      "  29/CD\n",
      "  mars/NNS\n",
      "  2018/CD\n",
      "  au/JJ\n",
      "  (ORGANIZATION Collège/NNP)\n",
      "  de/FW\n",
      "  (GPE France/NNP)\n",
      "  ./.\n",
      "  Au/NNP\n",
      "  début/NN\n",
      "  des/NNS\n",
      "  années/IN\n",
      "  2000/CD\n",
      "  ,/,\n",
      "  des/VBZ\n",
      "  sociologues/NNS\n",
      "  liés/RBR\n",
      "  à/NNP\n",
      "  l'EHESS/NN\n",
      "  ,/,\n",
      "  spécialistes/VBZ\n",
      "  de/FW\n",
      "  l'analyse/FW\n",
      "  de/FW\n",
      "  corpus/NN\n",
      "  ,/,\n",
      "  expérimentent/JJ\n",
      "  la/NN\n",
      "  mise/NN\n",
      "  au/NN\n",
      "  point/NN\n",
      "  d'un/NN\n",
      "  «/NNP\n",
      "  sociologue/NN\n",
      "  numérique/NN\n",
      "  »/NNP\n",
      "  appelé/NN\n",
      "  (PERSON Marlowe/NNP)\n",
      "  qui/NN\n",
      "  crée/NN\n",
      "  un/JJ\n",
      "  pont/NN\n",
      "  entre/JJ\n",
      "  intelligence/NN\n",
      "  artificielle/NN\n",
      "  et/NN\n",
      "  sciences/NNS\n",
      "  sociales/NNS\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "ner_fr = ne_chunk(tags_fr) # On applique la fonction de reconnaissance d’entités de nltk\n",
    "print (ner_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produit Scalaire\n",
    "## $ < \\vec{u} ,  \\vec{v} > = u * v =  \\sum_{i=1}^{n} u_i * v_i $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def my_scalar_product(u, v):\n",
    "    # sum( [x * y for x, y in zip(u, v)] )\n",
    "    if len(u) >= 2 :\n",
    "        res = sum(u[0] * v[0], scalar_product(u[1:], v[1:]) )\n",
    "    return  res\n",
    "\n",
    "def scalar_product(u, v):\n",
    "    return np.sum(u * v)\n",
    "\n",
    "v = np.array([ 1, 1])\n",
    "w = np.array([ -1, 1])\n",
    "\n",
    "#print(my_scalar_product(v, w))\n",
    "print(scalar_product(v, w))\n",
    "\n",
    "w = np.array([ 2, 2])\n",
    "print(scalar_product(v, w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de la cosinus similiarité \n",
    "mesure de la similiarité de deux vecteur qui ne dépends pas de leur longueur.\n",
    "# $ cos( \\theta ) = \\frac{ < \\vec{u} ,  \\vec{v} > }{ || \\vec{u} || * || \\vec{v} || } $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8164965809277261"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norme(x):\n",
    "    return (scalar_product(x, x)**0.5)\n",
    "#print(norme(np.array([ 1, 0])))\n",
    "\n",
    "def cos_similiarite (u, v):\n",
    "    #colinearite = np.linalg.norm(u) * np.linalg.norm(v)\n",
    "    colinearite =  norme(u) * norme(v)\n",
    "    return scalar_product(u, v) / colinearite\n",
    "\n",
    "v = np.array([ 1, 1])\n",
    "w = np.array([ -1, 1])\n",
    "print(cos_similiarite(v, w))\n",
    "\n",
    "v = np.array([ 1, 1, 1])\n",
    "w = np.array([ 1, 1, 4])\n",
    "cos_similiarite(v, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency, Inverse Document Frequency)\n",
    "\n",
    "Voir le ficier test.py pour les tests unitaires\n",
    "\n",
    "https://stevenloria.com/tf-idf/\n",
    "\n",
    "## $ TFIDF(word) = termFrequency(word) * inverseDocumentFrequency(word) $\n",
    "\n",
    "termFrequency(word) = nb de fois qu'apparet word dans un document / nb de mot total du document\n",
    "\n",
    "inverseDocumentFrequency(word) = log(nb de document/nb de document qui contienne word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-70c29980aedd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msplit_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\W+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msplit_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\W+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msplit_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\W+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msplit_4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\W+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msplit_5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\W+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "split_1 = re.split(\"\\W+\", text_1)\n",
    "split_2 = re.split(\"\\W+\", text_2)\n",
    "split_3 = re.split(\"\\W+\", text_3)\n",
    "split_4 = re.split(\"\\W+\", text_4)\n",
    "split_5 = re.split(\"\\W+\", text_5)\n",
    "split_6 = re.split(\"\\W+\", text_6)\n",
    "\n",
    "wordDict_1 = dict.fromkeys(set(split_1).union(set(split_2)).union(set(split_3)).union(set(split_4)).union(set(split_5)).union(set(split_6)), 0)\n",
    "wordDict_2 = dict.fromkeys(set(split_1).union(set(split_2),set(split_3),set(split_4),set(split_5),set(split_6)), 0)\n",
    "wordDict_3 = dict.fromkeys(set(split_1).union(set(split_2),set(split_3),set(split_4),set(split_5),set(split_6)), 0)\n",
    "wordDict_4 = dict.fromkeys(set(split_1).union(set(split_2),set(split_3),set(split_4),set(split_5),set(split_6)), 0)\n",
    "wordDict_5 = dict.fromkeys(set(split_1).union(set(split_2),set(split_3),set(split_4),set(split_5),set(split_6)), 0)\n",
    "wordDict_6 = dict.fromkeys(set(split_1).union(set(split_2),set(split_3),set(split_4),set(split_5),set(split_6)), 0)\n",
    "\n",
    "\n",
    "for w in split_1:\n",
    "    wordDict_1[w]+=1\n",
    "for w in split_2:\n",
    "    wordDict_2[w]+=1\n",
    "for w in split_3:\n",
    "    wordDict_3[w]+=1\n",
    "for w in split_4:\n",
    "    wordDict_4[w]+=1\n",
    "for w in split_5:\n",
    "    wordDict_5[w]+=1\n",
    "for w in split_6:\n",
    "    wordDict_6[w]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0.006756756756756757, 'création': 0.006756756756756757, 'obtenue': 0.0, 'bouées': 0.0, 'jusqu': 0.0, 'datant': 0.0, 'veut': 0.0, 'ont': 0.0, 'radiosondages': 0.0, 'crée': 0.006756756756756757, 'sociologue': 0.006756756756756757, 'IJCAI': 0.006756756756756757, 'Humanity': 0.006756756756756757, 'mesures': 0.0, 'beaucoup': 0.0, 'dès': 0.0, 'poisson': 0.0, 'cent': 0.0, 'morale': 0.0, 'en': 0.0472972972972973, 'La': 0.0, 'mars': 0.006756756756756757, 'poissons': 0.0, 'Toutes': 0.0, 'qu': 0.0, 'numérique': 0.006756756756756757, 'capteurs': 0.0, 'AFIA': 0.006756756756756757, 'toute': 0.0, 'Huet': 0.006756756756756757, 'laissée': 0.0, 'autant': 0.0, 'Gérard': 0.006756756756756757, 'doit': 0.0, 'difficile': 0.0, 'décédés': 0.0, 'M': 0.0, 'Une': 0.0, 'informations': 0.0, '1993': 0.006756756756756757, 'se': 0.0, 'a': 0.0, 'part': 0.0, 'avance': 0.0, 'jamais': 0.0, 'importante': 0.0, 'congrès': 0.006756756756756757, 'national': 0.006756756756756757, 'avoir': 0.0, 'avions': 0.0, 'savante': 0.006756756756756757, 'établir': 0.0, 'petits': 0.0, 'contraint': 0.0, 'dont': 0.0, 'bruit': 0.0, 'trois': 0.0, 'fournis': 0.0, 'Il': 0.0, 'Picard': 0.006756756756756757, 'ancrées': 0.0, 'sciences': 0.006756756756756757, 'entre': 0.013513513513513514, '10': 0.0, 'case': 0.0, 'but': 0.0, 'cours': 0.0, 'PRC35': 0.006756756756756757, 'peur': 0.0, 'sentiment': 0.0, 'recueillies': 0.0, 'prévisions': 0.0, 'puis': 0.0, 'après': 0.0, 'correction': 0.0, 'surtout': 0.0, 'lançant': 0.0, 'conférences': 0.006756756756756757, 'être': 0.0, 'XVIème': 0.0, 'autres': 0.006756756756756757, 'terrible': 0.0, 'début': 0.006756756756756757, 'où': 0.0, 'S': 0.0, 'provoquer': 0.0, 'règle': 0.0, 'créatures': 0.0, 'survivre': 0.0, 'plus': 0.0, 'loin': 0.0, 'aller': 0.0, 'détection': 0.0, 'faire': 0.0, 'fuir': 0.0, 'son': 0.0, 'créé': 0.006756756756756757, 'Fontaine': 0.0, 'Simon': 0.006756756756756757, 'invente': 0.0, 'il': 0.006756756756756757, 'augmenter': 0.0, 'ligne': 0.0, 'caractériser': 0.0, 'de': 0.04054054054054054, 'Reconnaissance': 0.006756756756756757, 'prévision': 0.0, 'respecter': 0.0, 'rare': 0.0, 'corps': 0.0, 'doses': 0.0, 'allégoriques': 0.0, 'l': 0.033783783783783786, 'France': 0.013513513513513514, 'Louis': 0.006756756756756757, 'anthropomorphes': 0.0, 'voler': 0.0, 'héritage': 0.0, 'fera': 0.0, 'nombre': 0.0, 'angoisse': 0.0, 'for': 0.006756756756756757, 'par': 0.0, 'état': 0.0, 'Voyons': 0.0, 'chez': 0.0, 'la': 0.02702702702702703, 'société': 0.006756756756756757, 'notion': 0.0, 'reçoit': 0.0, 'esprit': 0.0, 'ensuite': 0.0, 'enseignement': 0.0, 'intelligence': 0.04054054054054054, 'école': 0.0, 'support': 0.0, '1694': 0.0, 'tente': 0.0, 'deux': 0.0, 'qui': 0.013513513513513514, 'Collège': 0.006756756756756757, 'utilisées': 0.0, 'jour': 0.0, 'temps': 0.0, 'combinées': 0.0, 'comme': 0.0, 'va': 0.0, 'scène': 0.0, 'commencer': 0.0, 'épouvante': 0.0, 'issues': 0.0, 'dérivantes': 0.0, '2018': 0.006756756756756757, 'familiaux': 0.0, 'République': 0.0, 'sa': 0.0, 'Environ': 0.0, 'commencent': 0.0, 'ésopique': 0.0, 'existe': 0.0, 'Chaque': 0.0, 'Car': 0.0, 'Modèle': 0.0, 'tour': 0.0, 'grands': 0.0, 'joueur': 0.0, 'parcours': 0.0, 'modèle': 0.0, 'mise': 0.006756756756756757, 'parents': 0.0, 'nécessaire': 0.0, 'menace': 0.0, 'quarante': 0.0, '1979': 0.006756756756756757, 'appâtant': 0.0, 'zone': 0.0, 'Fables': 0.0, 'utilisés': 0.0, 'En': 0.013513513513513514, 'fables': 0.0, 'que': 0.0, 'première': 0.0, 'jésuites': 0.0, 'modèles': 0.0, 'Ce': 0.0, 'apporte': 0.0, 'IA': 0.006756756756756757, 'thriller': 0.0, 'générale': 0.0, 'années': 0.006756756756756757, 'constitue': 0.0, 'utiliser': 0.0, 'prévoir': 0.0, 'chiffre': 0.0, 'connaître': 0.0, 'Dans': 0.0, 'vers': 0.0, '22': 0.0, 'leurs': 0.0, 'prévisionnistes': 0.0, 'on': 0.0, 'organise': 0.006756756756756757, 'publiés': 0.0, 'déjà': 0.0, 'nationales': 0.006756756756756757, 'satellites': 0.0, 'situation': 0.0, 'appelé': 0.006756756756756757, 'analyse': 0.006756756756756757, 'frère': 0.0, 'Oie': 0.0, 'répulsion': 0.0, 'principal': 0.0, 'apologues': 0.0, 'dés': 0.0, 'navires': 0.0, 'sur': 0.0, 'style': 0.0, 'genre': 0.0, 'corpus': 0.006756756756756757, 'finissent': 0.0, 'moderne': 0.0, 'stations': 0.0, 'Chambéry': 0.006756756756756757, 'Association': 0.006756756756756757, 'artificielle': 0.04054054054054054, 'ils': 0.0, 'données': 0.0, 'observations': 0.0, 'commerce': 0.0, 'd': 0.013513513513513514, 'au': 0.013513513513513514, 'Babrius': 0.0, 'guerre': 0.0, 'sans': 0.0, 'auteur': 0.0, 'dissocier': 0.0, 'pion': 0.0, 'jeune': 0.0, 'pas': 0.0, 'conférence': 0.013513513513513514, 'deviennent': 0.0, 'Troisième': 0.0, 'laquelle': 0.0, '90': 0.0, 'ce': 0.0, 'plupart': 0.0, 'Claude': 0.013513513513513514, 'maison': 0.0, 'pêche': 0.0, 'annuel': 0.006756756756756757, 'aussi': 0.0, 'Colmerauer': 0.006756756756756757, 'joue': 0.0, 'Pour': 0.0, 'spécialistes': 0.006756756756756757, 'lien': 0.006756756756756757, 'peu': 0.0, 'toujours': 0.0, 'aujourd': 0.0, 'Un': 0.006756756756756757, 'française': 0.006756756756756757, 'dans': 0.0, 'amorçage': 0.0, 'Marlowe': 0.006756756756756757, 'pour': 0.006756756756756757, 'surnaturel': 0.0, 'sol': 0.0, 'moindre': 0.0, 'services': 0.0, 'attaquent': 0.0, 'GRECO': 0.006756756756756757, 'veulent': 0.0, 'mystérieuses': 0.0, 'les': 0.006756756756756757, 'français': 0.0, 'propos': 0.0, 'film': 0.0, 'Phèdre': 0.0, 'ignorance': 0.0, 'suivant': 0.0, 'inspirées': 0.0, 'animer': 0.0, 'trop': 0.0, '1668': 0.0, 'évangélique': 0.0, 'incontournable': 0.0, 'rupture': 0.0, 'ainsi': 0.0, 'point': 0.006756756756756757, 'tout': 0.0, 'didactiques': 0.0, 'météorologiques': 0.0, 'atmosphère': 0.0, 'chacun': 0.0, '1983': 0.006756756756756757, 'étape': 0.0, 'midi': 0.0, 'Suivant': 0.0, 'installés': 0.0, 'quitter': 0.0, 'Jacques': 0.006756756756756757, 'sous': 0.0, 'millions': 0.0, 'L': 0.0, 'AI': 0.006756756756756757, 'sociales': 0.006756756756756757, 'détails': 0.0, 'récentes': 0.0, 'organisée': 0.006756756756756757, 'pont': 0.006756756756756757, 'Pitrat': 0.006756756756756757, 'également': 0.0, 'y': 0.0, 'donne': 0.006756756756756757, 'assimilation': 0.0, 'demain': 0.0, '1989': 0.006756756756756757, 'expérimentent': 0.006756756756756757, 'recueils': 0.0, 'appelées': 0.0, 'leur': 0.0, 'siècle': 0.0, 'entendent': 0.0, '2': 0.0, 'jeu': 0.0, 'selon': 0.0, 'traitées': 0.0, '2000': 0.006756756756756757, 'parle': 0.0, 'liés': 0.006756756756756757, '29': 0.006756756756756757, 'mettent': 0.0, 'ne': 0.0, 'Toulouse': 0.006756756756756757, 'erreurs': 0.0, 'observation': 0.0, 'extraire': 0.0, 'Ésope': 0.0, 'Au': 0.006756756756756757, 'restants': 0.0, 'résultats': 0.0, 'globe': 0.0, 'initial': 0.0, 'homme': 0.0, 'éclats': 0.0, 'une': 0.006756756756756757, 'François': 0.006756756756756757, 'le': 0.006756756756756757, 'souvent': 0.0, 'choisies': 0.0, 'ou': 0.0, 'tombe': 0.0, 'là': 0.0, 'Laurière': 0.006756756756756757, 'saura': 0.0, 'hui': 0.0, 'sont': 0.006756756756756757, 'chaque': 0.0, 'proviennent': 0.0, 'règles': 0.0, 'issue': 0.0, 'formes': 0.006756756756756757, 'Alain': 0.006756756756756757, 'recluse': 0.0, '1763': 0.0, 'traditions': 0.0, 'Retrouvez': 0.0, 'bientôt': 0.0, 'actualité': 0.0, 'et': 0.02702702702702703, 'tard': 0.0, 'cas': 0.0, 'à': 0.02702702702702703, 'créer': 0.0, 'Météo': 0.0, 'EHESS': 0.006756756756756757, 'Logo': 0.006756756756756757, 'soeur': 0.0, 'Trop': 0.0, 'très': 0.0, 'étendue': 0.0, 'Le': 0.0, 'Les': 0.0, 'horreur': 0.0, 'éventuelles': 0.0, 'humaniste': 0.0, 'embarqués': 0.0, 'est': 0.006756756756756757, 'animaux': 0.0, 'organisation': 0.006756756756756757, 'autre': 0.0, 'amorce': 0.0, 'ensemble': 0.0, 'cette': 0.0, 'Plus': 0.0, 'parfois': 0.0, 'fait': 0.0, 'cinématographique': 0.0, 'pionniers': 0.006756756756756757, 'objectif': 0.0, 'quantité': 0.0, 'famille': 0.0, 'mises': 0.0, 'XVIIIe': 0.0, 'sociologues': 0.006756756756756757, 'un': 0.02027027027027027, 'des': 0.02027027027027027, 'Jean': 0.013513513513513514, 'naissance': 0.006756756756756757, 'faut': 0.0, 'suivi': 0.0, 'fantastique': 0.0, 'nourriture': 0.0, 'du': 0.0, 'vous': 0.0, 'avec': 0.006756756756756757, 'ces': 0.0, 'précepteurs': 0.0, 'spectateur': 0.0, 'simplement': 0.0, 'enseignant': 0.0, 'utiles': 0.0, 'primaire': 0.0, 'secret': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# TermFrequency <=> CountVectorizer\n",
    "# nombre de fois qu'apparet un mot dans un document sur le nombre de mot total du document\n",
    "# document.count(word) / len(document)\n",
    "def term_frequency(wordDict, document):\n",
    "    tfDict={}\n",
    "    for w, valcount in wordDict.items():\n",
    "        tfDict[w] = valcount / float(len(document))\n",
    "    return tfDict\n",
    "\n",
    "#print(term_frequency(wordDict_1, split_1))\n",
    "#print(term_frequency(wordDict_2, split_2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_document_frequencies(document_list):\n",
    "    idfDict = dict.fromkeys(document_list[0].keys(), 0)\n",
    "    #on compte le nombre de document conenant un mot \n",
    "    for doc in document_list:\n",
    "        for key, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[key] += 1\n",
    "                \n",
    "    for clef, val in idfDict.items() :\n",
    "        idfDict[clef] = math.log(len(document_list)/float(val))\n",
    "    \n",
    "    return idfDict\n",
    "\n",
    "#print(inverse_document_frequencies([wordDict_1, wordDict_2, wordDict_3, wordDict_4, wordDict_5, wordDict_6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(word, wordDict, document_list):\n",
    "    tf_idf = {}\n",
    "    tf = term_frequency(wordDict, word)\n",
    "    idf = inverse_document_frequencies(document_list)\n",
    "    for key, val in tf.items() :\n",
    "        tf_idf[key] = val * idf[key]\n",
    "    return  tf_idf\n",
    "\n",
    "tfidf_1 = tf_idf(split_1, wordDict_1, [wordDict_1, wordDict_2, wordDict_3, wordDict_4, wordDict_5, wordDict_6])\n",
    "#print(tfidf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 0.0),\n",
       " ('obtenue', 0.0),\n",
       " ('bouées', 0.0),\n",
       " ('jusqu', 0.0),\n",
       " ('datant', 0.0),\n",
       " ('veut', 0.0),\n",
       " ('ont', 0.0),\n",
       " ('radiosondages', 0.0),\n",
       " ('mesures', 0.0),\n",
       " ('beaucoup', 0.0),\n",
       " ('dès', 0.0),\n",
       " ('poisson', 0.0),\n",
       " ('cent', 0.0),\n",
       " ('morale', 0.0),\n",
       " ('en', 0.0),\n",
       " ('La', 0.0),\n",
       " ('poissons', 0.0),\n",
       " ('Toutes', 0.0),\n",
       " ('qu', 0.0),\n",
       " ('capteurs', 0.0),\n",
       " ('toute', 0.0),\n",
       " ('laissée', 0.0),\n",
       " ('autant', 0.0),\n",
       " ('doit', 0.0),\n",
       " ('difficile', 0.0),\n",
       " ('décédés', 0.0),\n",
       " ('M', 0.0),\n",
       " ('Une', 0.0),\n",
       " ('informations', 0.0),\n",
       " ('se', 0.0),\n",
       " ('a', 0.0),\n",
       " ('part', 0.0),\n",
       " ('avance', 0.0),\n",
       " ('jamais', 0.0),\n",
       " ('importante', 0.0),\n",
       " ('avoir', 0.0),\n",
       " ('avions', 0.0),\n",
       " ('établir', 0.0),\n",
       " ('petits', 0.0),\n",
       " ('contraint', 0.0),\n",
       " ('dont', 0.0),\n",
       " ('bruit', 0.0),\n",
       " ('trois', 0.0),\n",
       " ('fournis', 0.0),\n",
       " ('Il', 0.0),\n",
       " ('ancrées', 0.0),\n",
       " ('10', 0.0),\n",
       " ('case', 0.0),\n",
       " ('but', 0.0),\n",
       " ('cours', 0.0),\n",
       " ('peur', 0.0),\n",
       " ('sentiment', 0.0),\n",
       " ('recueillies', 0.0),\n",
       " ('prévisions', 0.0),\n",
       " ('puis', 0.0),\n",
       " ('après', 0.0),\n",
       " ('correction', 0.0),\n",
       " ('surtout', 0.0),\n",
       " ('lançant', 0.0),\n",
       " ('être', 0.0),\n",
       " ('XVIème', 0.0),\n",
       " ('terrible', 0.0),\n",
       " ('où', 0.0),\n",
       " ('S', 0.0),\n",
       " ('provoquer', 0.0),\n",
       " ('règle', 0.0),\n",
       " ('créatures', 0.0),\n",
       " ('survivre', 0.0),\n",
       " ('plus', 0.0),\n",
       " ('loin', 0.0),\n",
       " ('aller', 0.0),\n",
       " ('détection', 0.0),\n",
       " ('faire', 0.0),\n",
       " ('fuir', 0.0),\n",
       " ('son', 0.0),\n",
       " ('Fontaine', 0.0),\n",
       " ('invente', 0.0),\n",
       " ('augmenter', 0.0),\n",
       " ('ligne', 0.0),\n",
       " ('caractériser', 0.0),\n",
       " ('de', 0.0),\n",
       " ('prévision', 0.0),\n",
       " ('respecter', 0.0),\n",
       " ('rare', 0.0),\n",
       " ('corps', 0.0),\n",
       " ('doses', 0.0),\n",
       " ('allégoriques', 0.0),\n",
       " ('l', 0.0),\n",
       " ('anthropomorphes', 0.0),\n",
       " ('voler', 0.0),\n",
       " ('héritage', 0.0),\n",
       " ('fera', 0.0),\n",
       " ('nombre', 0.0),\n",
       " ('angoisse', 0.0),\n",
       " ('par', 0.0),\n",
       " ('état', 0.0),\n",
       " ('Voyons', 0.0),\n",
       " ('chez', 0.0),\n",
       " ('la', 0.0),\n",
       " ('notion', 0.0),\n",
       " ('reçoit', 0.0),\n",
       " ('esprit', 0.0),\n",
       " ('ensuite', 0.0),\n",
       " ('enseignement', 0.0),\n",
       " ('école', 0.0),\n",
       " ('support', 0.0),\n",
       " ('1694', 0.0),\n",
       " ('tente', 0.0),\n",
       " ('deux', 0.0),\n",
       " ('utilisées', 0.0),\n",
       " ('jour', 0.0),\n",
       " ('temps', 0.0),\n",
       " ('combinées', 0.0),\n",
       " ('comme', 0.0),\n",
       " ('va', 0.0),\n",
       " ('scène', 0.0),\n",
       " ('commencer', 0.0),\n",
       " ('épouvante', 0.0),\n",
       " ('issues', 0.0),\n",
       " ('dérivantes', 0.0),\n",
       " ('familiaux', 0.0),\n",
       " ('République', 0.0),\n",
       " ('sa', 0.0),\n",
       " ('Environ', 0.0),\n",
       " ('commencent', 0.0),\n",
       " ('ésopique', 0.0),\n",
       " ('existe', 0.0),\n",
       " ('Chaque', 0.0),\n",
       " ('Car', 0.0),\n",
       " ('Modèle', 0.0),\n",
       " ('tour', 0.0),\n",
       " ('grands', 0.0),\n",
       " ('joueur', 0.0),\n",
       " ('parcours', 0.0),\n",
       " ('modèle', 0.0),\n",
       " ('parents', 0.0),\n",
       " ('nécessaire', 0.0),\n",
       " ('menace', 0.0),\n",
       " ('quarante', 0.0),\n",
       " ('appâtant', 0.0),\n",
       " ('zone', 0.0),\n",
       " ('Fables', 0.0),\n",
       " ('utilisés', 0.0),\n",
       " ('fables', 0.0),\n",
       " ('que', 0.0),\n",
       " ('première', 0.0),\n",
       " ('jésuites', 0.0),\n",
       " ('modèles', 0.0),\n",
       " ('Ce', 0.0),\n",
       " ('apporte', 0.0),\n",
       " ('thriller', 0.0),\n",
       " ('générale', 0.0),\n",
       " ('constitue', 0.0),\n",
       " ('utiliser', 0.0),\n",
       " ('prévoir', 0.0),\n",
       " ('chiffre', 0.0),\n",
       " ('connaître', 0.0),\n",
       " ('Dans', 0.0),\n",
       " ('vers', 0.0),\n",
       " ('22', 0.0),\n",
       " ('leurs', 0.0),\n",
       " ('prévisionnistes', 0.0),\n",
       " ('on', 0.0),\n",
       " ('publiés', 0.0),\n",
       " ('déjà', 0.0),\n",
       " ('satellites', 0.0),\n",
       " ('situation', 0.0),\n",
       " ('frère', 0.0),\n",
       " ('Oie', 0.0),\n",
       " ('répulsion', 0.0),\n",
       " ('principal', 0.0),\n",
       " ('apologues', 0.0),\n",
       " ('dés', 0.0),\n",
       " ('navires', 0.0),\n",
       " ('sur', 0.0),\n",
       " ('style', 0.0),\n",
       " ('genre', 0.0),\n",
       " ('finissent', 0.0),\n",
       " ('moderne', 0.0),\n",
       " ('stations', 0.0),\n",
       " ('ils', 0.0),\n",
       " ('données', 0.0),\n",
       " ('observations', 0.0),\n",
       " ('commerce', 0.0),\n",
       " ('d', 0.0),\n",
       " ('Babrius', 0.0),\n",
       " ('guerre', 0.0),\n",
       " ('sans', 0.0),\n",
       " ('auteur', 0.0),\n",
       " ('dissocier', 0.0),\n",
       " ('pion', 0.0),\n",
       " ('jeune', 0.0),\n",
       " ('pas', 0.0),\n",
       " ('deviennent', 0.0),\n",
       " ('Troisième', 0.0),\n",
       " ('laquelle', 0.0),\n",
       " ('90', 0.0),\n",
       " ('ce', 0.0),\n",
       " ('plupart', 0.0),\n",
       " ('maison', 0.0),\n",
       " ('pêche', 0.0),\n",
       " ('aussi', 0.0),\n",
       " ('joue', 0.0),\n",
       " ('Pour', 0.0),\n",
       " ('peu', 0.0),\n",
       " ('toujours', 0.0),\n",
       " ('aujourd', 0.0),\n",
       " ('dans', 0.0),\n",
       " ('amorçage', 0.0),\n",
       " ('surnaturel', 0.0),\n",
       " ('sol', 0.0),\n",
       " ('moindre', 0.0),\n",
       " ('services', 0.0),\n",
       " ('attaquent', 0.0),\n",
       " ('veulent', 0.0),\n",
       " ('mystérieuses', 0.0),\n",
       " ('les', 0.0),\n",
       " ('français', 0.0),\n",
       " ('propos', 0.0),\n",
       " ('film', 0.0),\n",
       " ('Phèdre', 0.0),\n",
       " ('ignorance', 0.0),\n",
       " ('suivant', 0.0),\n",
       " ('inspirées', 0.0),\n",
       " ('animer', 0.0),\n",
       " ('trop', 0.0),\n",
       " ('1668', 0.0),\n",
       " ('évangélique', 0.0),\n",
       " ('incontournable', 0.0),\n",
       " ('rupture', 0.0),\n",
       " ('ainsi', 0.0),\n",
       " ('tout', 0.0),\n",
       " ('didactiques', 0.0),\n",
       " ('météorologiques', 0.0),\n",
       " ('atmosphère', 0.0),\n",
       " ('chacun', 0.0),\n",
       " ('étape', 0.0),\n",
       " ('midi', 0.0),\n",
       " ('Suivant', 0.0),\n",
       " ('installés', 0.0),\n",
       " ('quitter', 0.0),\n",
       " ('sous', 0.0),\n",
       " ('millions', 0.0),\n",
       " ('L', 0.0),\n",
       " ('détails', 0.0),\n",
       " ('récentes', 0.0),\n",
       " ('également', 0.0),\n",
       " ('y', 0.0),\n",
       " ('assimilation', 0.0),\n",
       " ('demain', 0.0),\n",
       " ('recueils', 0.0),\n",
       " ('appelées', 0.0),\n",
       " ('leur', 0.0),\n",
       " ('siècle', 0.0),\n",
       " ('entendent', 0.0),\n",
       " ('2', 0.0),\n",
       " ('jeu', 0.0),\n",
       " ('selon', 0.0),\n",
       " ('traitées', 0.0),\n",
       " ('parle', 0.0),\n",
       " ('mettent', 0.0),\n",
       " ('ne', 0.0),\n",
       " ('erreurs', 0.0),\n",
       " ('observation', 0.0),\n",
       " ('extraire', 0.0),\n",
       " ('Ésope', 0.0),\n",
       " ('restants', 0.0),\n",
       " ('résultats', 0.0),\n",
       " ('globe', 0.0),\n",
       " ('initial', 0.0),\n",
       " ('homme', 0.0),\n",
       " ('éclats', 0.0),\n",
       " ('le', 0.0),\n",
       " ('souvent', 0.0),\n",
       " ('choisies', 0.0),\n",
       " ('ou', 0.0),\n",
       " ('tombe', 0.0),\n",
       " ('là', 0.0),\n",
       " ('saura', 0.0),\n",
       " ('hui', 0.0),\n",
       " ('chaque', 0.0),\n",
       " ('proviennent', 0.0),\n",
       " ('règles', 0.0),\n",
       " ('issue', 0.0),\n",
       " ('recluse', 0.0),\n",
       " ('1763', 0.0),\n",
       " ('traditions', 0.0),\n",
       " ('Retrouvez', 0.0),\n",
       " ('bientôt', 0.0),\n",
       " ('actualité', 0.0),\n",
       " ('et', 0.0),\n",
       " ('tard', 0.0),\n",
       " ('cas', 0.0),\n",
       " ('créer', 0.0),\n",
       " ('Météo', 0.0),\n",
       " ('soeur', 0.0),\n",
       " ('Trop', 0.0),\n",
       " ('très', 0.0),\n",
       " ('étendue', 0.0),\n",
       " ('Le', 0.0),\n",
       " ('Les', 0.0),\n",
       " ('horreur', 0.0),\n",
       " ('éventuelles', 0.0),\n",
       " ('humaniste', 0.0),\n",
       " ('embarqués', 0.0),\n",
       " ('animaux', 0.0),\n",
       " ('autre', 0.0),\n",
       " ('amorce', 0.0),\n",
       " ('ensemble', 0.0),\n",
       " ('cette', 0.0),\n",
       " ('Plus', 0.0),\n",
       " ('parfois', 0.0),\n",
       " ('fait', 0.0),\n",
       " ('cinématographique', 0.0),\n",
       " ('objectif', 0.0),\n",
       " ('quantité', 0.0),\n",
       " ('famille', 0.0),\n",
       " ('mises', 0.0),\n",
       " ('XVIIIe', 0.0),\n",
       " ('faut', 0.0),\n",
       " ('suivi', 0.0),\n",
       " ('fantastique', 0.0),\n",
       " ('nourriture', 0.0),\n",
       " ('du', 0.0),\n",
       " ('vous', 0.0),\n",
       " ('ces', 0.0),\n",
       " ('précepteurs', 0.0),\n",
       " ('spectateur', 0.0),\n",
       " ('simplement', 0.0),\n",
       " ('enseignant', 0.0),\n",
       " ('utiles', 0.0),\n",
       " ('primaire', 0.0),\n",
       " ('secret', 0.0),\n",
       " ('une', 0.0012319024107699636),\n",
       " ('il', 0.0027396291088389486),\n",
       " ('pour', 0.0027396291088389486),\n",
       " ('sont', 0.0027396291088389486),\n",
       " ('est', 0.0027396291088389486),\n",
       " ('autres', 0.007423056004514256),\n",
       " ('début', 0.007423056004514256),\n",
       " ('Un', 0.007423056004514256),\n",
       " ('liés', 0.007423056004514256),\n",
       " ('avec', 0.007423056004514256),\n",
       " ('un', 0.008218887326516846),\n",
       " ('des', 0.008218887326516846),\n",
       " ('France', 0.009366853791350613),\n",
       " ('au', 0.009366853791350613),\n",
       " ('à', 0.010958516435355795),\n",
       " ('création', 0.012106482900189562),\n",
       " ('crée', 0.012106482900189562),\n",
       " ('sociologue', 0.012106482900189562),\n",
       " ('IJCAI', 0.012106482900189562),\n",
       " ('Humanity', 0.012106482900189562),\n",
       " ('mars', 0.012106482900189562),\n",
       " ('numérique', 0.012106482900189562),\n",
       " ('AFIA', 0.012106482900189562),\n",
       " ('Huet', 0.012106482900189562),\n",
       " ('Gérard', 0.012106482900189562),\n",
       " ('1993', 0.012106482900189562),\n",
       " ('congrès', 0.012106482900189562),\n",
       " ('national', 0.012106482900189562),\n",
       " ('savante', 0.012106482900189562),\n",
       " ('Picard', 0.012106482900189562),\n",
       " ('sciences', 0.012106482900189562),\n",
       " ('PRC35', 0.012106482900189562),\n",
       " ('conférences', 0.012106482900189562),\n",
       " ('créé', 0.012106482900189562),\n",
       " ('Simon', 0.012106482900189562),\n",
       " ('Reconnaissance', 0.012106482900189562),\n",
       " ('Louis', 0.012106482900189562),\n",
       " ('for', 0.012106482900189562),\n",
       " ('société', 0.012106482900189562),\n",
       " ('Collège', 0.012106482900189562),\n",
       " ('2018', 0.012106482900189562),\n",
       " ('mise', 0.012106482900189562),\n",
       " ('1979', 0.012106482900189562),\n",
       " ('IA', 0.012106482900189562),\n",
       " ('années', 0.012106482900189562),\n",
       " ('organise', 0.012106482900189562),\n",
       " ('nationales', 0.012106482900189562),\n",
       " ('appelé', 0.012106482900189562),\n",
       " ('analyse', 0.012106482900189562),\n",
       " ('corpus', 0.012106482900189562),\n",
       " ('Chambéry', 0.012106482900189562),\n",
       " ('Association', 0.012106482900189562),\n",
       " ('annuel', 0.012106482900189562),\n",
       " ('Colmerauer', 0.012106482900189562),\n",
       " ('spécialistes', 0.012106482900189562),\n",
       " ('lien', 0.012106482900189562),\n",
       " ('française', 0.012106482900189562),\n",
       " ('Marlowe', 0.012106482900189562),\n",
       " ('GRECO', 0.012106482900189562),\n",
       " ('point', 0.012106482900189562),\n",
       " ('1983', 0.012106482900189562),\n",
       " ('Jacques', 0.012106482900189562),\n",
       " ('AI', 0.012106482900189562),\n",
       " ('sociales', 0.012106482900189562),\n",
       " ('organisée', 0.012106482900189562),\n",
       " ('pont', 0.012106482900189562),\n",
       " ('Pitrat', 0.012106482900189562),\n",
       " ('donne', 0.012106482900189562),\n",
       " ('1989', 0.012106482900189562),\n",
       " ('expérimentent', 0.012106482900189562),\n",
       " ('2000', 0.012106482900189562),\n",
       " ('29', 0.012106482900189562),\n",
       " ('Toulouse', 0.012106482900189562),\n",
       " ('Au', 0.012106482900189562),\n",
       " ('François', 0.012106482900189562),\n",
       " ('Laurière', 0.012106482900189562),\n",
       " ('formes', 0.012106482900189562),\n",
       " ('Alain', 0.012106482900189562),\n",
       " ('EHESS', 0.012106482900189562),\n",
       " ('Logo', 0.012106482900189562),\n",
       " ('organisation', 0.012106482900189562),\n",
       " ('pionniers', 0.012106482900189562),\n",
       " ('sociologues', 0.012106482900189562),\n",
       " ('naissance', 0.012106482900189562),\n",
       " ('entre', 0.014846112009028512),\n",
       " ('qui', 0.014846112009028512),\n",
       " ('En', 0.014846112009028512),\n",
       " ('Jean', 0.014846112009028512),\n",
       " ('conférence', 0.024212965800379124),\n",
       " ('Claude', 0.024212965800379124),\n",
       " ('intelligence', 0.07263889740113737),\n",
       " ('artificielle', 0.07263889740113737)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator \n",
    "sorted(tfidf_1.items(),key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POO TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TFIDF(object):\n",
    "    #constructeur\n",
    "    def __init__(self, word, wordDict, document_list):\n",
    "        self.word = word\n",
    "        self.wordDict = wordDict\n",
    "        self.document_list = document_list\n",
    "    \n",
    "    # methode qui calcule le TF d'un document\n",
    "    def add_document(self, mot, document):\n",
    "        tf = document.count(mot) / len(document)\n",
    "        pass\n",
    "    \n",
    "    #methode qui verifie le cosinus similaritie d'un mot\n",
    "    #le mot\n",
    "    def query(self, dico):\n",
    "        cos_similiaritie()\n",
    "        pass\n",
    "        \n",
    "    def cos_similiarite (self, u, v):\n",
    "        #colinearite = np.linalg.norm(u) * np.linalg.norm(v)\n",
    "        colinearite =  norme(u) * norme(v)\n",
    "        return scalar_product(u, v) / colinearite\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f3e8d150a195>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mQuant\u001b[0m \u001b[0maux\u001b[0m \u001b[0mtisanes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcertaines\u001b[0m \u001b[0mplantes\u001b[0m \u001b[0msont\u001b[0m \u001b[0mcontre\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mindiquées\u001b[0m \u001b[0mpour\u001b[0m \u001b[0mles\u001b[0m \u001b[0mfemmes\u001b[0m \u001b[0menceintes\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mVoici\u001b[0m \u001b[0mles\u001b[0m \u001b[0mprincipales\u001b[0m \u001b[0mrecommandations\u001b[0m \u001b[0mà\u001b[0m \u001b[0mce\u001b[0m \u001b[0msujet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \"\"\"\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0msplit_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\W+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mwordDict_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "text_x=\"\"\" Il est important de boire suffisamment durant la grossesse : au moins 1 litre et demi par jour. \n",
    "Boire régulièrement permet une bonne hydratation et facilite l’élimination des déchets du corps de la mère et de celui du bébé dans l’urine. \n",
    "Avec les fibres alimentaires, l’eau aide à prévenir la constipation. Les femmes qui ont de l’enflure aux pieds à cause de la rétention d’eau doivent boire tout autant.\n",
    "En effet, l’enflure dépend très peu de la quantité de liquide qui est bu.\n",
    "L’eau est la meilleure des boissons. Les jus de fruits et de légumes, les bouillons, les soupes et le lait, par exemple, contribuent à l’apport total en eau. \n",
    "Toutefois, en raison de la caféine qu’ils contiennent, il y a des restrictions concernant le café, le thé, les boissons gazeuses et les boissons énergisantes. \n",
    "Quant aux tisanes, certaines plantes sont contre-indiquées pour les femmes enceintes. Voici les principales recommandations à ce sujet.\n",
    "\"\"\"\n",
    "split_x = re.split(\"\\W+\", text_x)\n",
    "wordDict_x = dict.fromkeys(set(split_1).union(set(split_2), set(split_3), set(split_4), set(split_5), set(split_6), set(split_x)), 0)\n",
    "\n",
    "for w in split_x:\n",
    "    wordDict_x[w]+=1\n",
    "\n",
    "docList = [wordDict_1, wordDict_2, wordDict_3, wordDict_4, wordDict_5, wordDict_6, wordDict_x]\n",
    "\n",
    "tf1 = TFIDF(split_x, wordDict_x, docList)\n",
    "print(tf1) #affichage de mon objet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
